<!DOCTYPE HTML>
<html lang="en" >
    <!-- Start book Python爬虫课程讲义 -->
    <head>
        <!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy的入门使用 | Python爬虫课程讲义</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        <meta name="author" content="BigCat">
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-tbfed-pagefooter/footer.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html" />
    
    
    <link rel="prev" href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html" />
    

        <!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
        
    <div class="book"
        data-level="7.2"
        data-chapter-title="scrapy的入门使用"
        data-filepath="files/07-scrapy爬虫框架/2.scrapy的入门使用.md"
        data-basepath="../.."
        data-revision="Thu Feb 28 2019 03:09:16 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        传智播客Python学科爬虫课件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="files/01-爬虫基础/index.html">
            
                
                    <a href="../../files/01-爬虫基础/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        网络爬虫知识基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="files/01-爬虫基础/1.爬虫概述.html">
            
                
                    <a href="../../files/01-爬虫基础/1.爬虫概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫概述与分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
            
                
                    <a href="../../files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        (了解) 通用爬虫和聚焦爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="files/01-爬虫基础/3.爬虫基础知识.html">
            
                
                    <a href="../../files/01-爬虫基础/3.爬虫基础知识.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        爬虫基础知识
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="files/01-爬虫基础/4.http协议复习.html">
            
                
                    <a href="../../files/01-爬虫基础/4.http协议复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        (复习) http协议复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="files/02-requests模块/index.html">
            
                
                    <a href="../../files/02-requests模块/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        HTTP请求处理工具：requests
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="files/02-requests模块/requests模块1.html">
            
                
                    <a href="../../files/02-requests模块/requests模块1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        requests模块处理的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="files/02-requests模块/requests模块2.html">
            
                
                    <a href="../../files/02-requests模块/requests模块2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        requests模块处理Cookie和Proxy高级功能
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="files/02-requests模块/requests模块3.html">
            
                
                    <a href="../../files/02-requests模块/requests模块3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        requests模块处理post请求与session会话保持
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="files/03-数据提取/index.html">
            
                
                    <a href="../../files/03-数据提取/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        HTTP数据提取工具：jsonpath 和 lxml/xpath
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="files/03-数据提取/1.数据提取概述.html">
            
                
                    <a href="../../files/03-数据提取/1.数据提取概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        数据提取概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="files/03-数据提取/2.数据提取-jsonpath模块.html">
            
                
                    <a href="../../files/03-数据提取/2.数据提取-jsonpath模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        数据提取-jsonpath模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="files/03-数据提取/3.数据提取-lxml模块.html">
            
                
                    <a href="../../files/03-数据提取/3.数据提取-lxml模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        数据提取-lxml模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="files/04-selenium的使用/index.html">
            
                
                    <a href="../../files/04-selenium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        web自动化测试工具：selenium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="files/04-selenium的使用/1.selenium的介绍.html">
            
                
                    <a href="../../files/04-selenium的使用/1.selenium的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        selenium的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
            
                
                    <a href="../../files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium定位获取标签对象并提取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="files/04-selenium的使用/3.selenium的其它使用方法.html">
            
                
                    <a href="../../files/04-selenium的使用/3.selenium的其它使用方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        selenium的其它使用方法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="files/05-抓包、反爬与反爬解决方案/index.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        抓包、反爬与反爬解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        常见的反爬手段、原理以及应对思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        打码平台处理验证码
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        chrome浏览器的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        js2py模块的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.5" data-path="files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        cookie池和代理池
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="files/06-mongodb数据库/index.html">
            
                
                    <a href="../../files/06-mongodb数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        MongoDB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="files/06-mongodb数据库/1.mongodb介绍和安装.html">
            
                
                    <a href="../../files/06-mongodb数据库/1.mongodb介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        mongodb介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="files/06-mongodb数据库/2.mongodb的简单使用.html">
            
                
                    <a href="../../files/06-mongodb数据库/2.mongodb的简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        mongodb的简单使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="files/06-mongodb数据库/3.mongodb的增删改查.html">
            
                
                    <a href="../../files/06-mongodb数据库/3.mongodb的增删改查.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        mongodb的增删改查
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="files/06-mongodb数据库/4.mongodb的索引操作.html">
            
                
                    <a href="../../files/06-mongodb数据库/4.mongodb的索引操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.4.</b>
                        
                        mongodb的索引操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="files/06-mongodb数据库/5.mongodb的权限管理.html">
            
                
                    <a href="../../files/06-mongodb数据库/5.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.5.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.6" data-path="files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
            
                
                    <a href="../../files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.6.</b>
                        
                        mongodb和python交互（pymongo模块的使用）
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="files/07-scrapy爬虫框架/index.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Scrapy爬虫框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7.2" data-path="files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.3.</b>
                        
                        scrapy构造并发送请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.4.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.6.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.7" data-path="files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.7.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.8" data-path="files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.8.</b>
                        
                        scrapy_redis原理分析并实现断点续爬以及分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.9" data-path="files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.9.</b>
                        
                        scrapy_splash组件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.10" data-path="files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.10.</b>
                        
                        scrapy的日志信息与配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.11" data-path="files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.11.</b>
                        
                        scrapyd部署scrapy项目
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="files/08-appium的使用/index.html">
            
                
                    <a href="../../files/08-appium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        移动端APP自动化测试工具：appium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="files/08-appium的使用/1.appium环境安装.html">
            
                
                    <a href="../../files/08-appium的使用/1.appium环境安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        appium环境安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
            
                
                    <a href="../../files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        利用appium自动控制移动设备并提取数据
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="files/09-项目-12306购票（requests）/index.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        项目：12306购票（requests）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        12306购票抓包分析以及任务分解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        处理验证码并完成登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.3" data-path="files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.3.</b>
                        
                        解析车站信息以及车辆信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.4" data-path="files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.4.</b>
                        
                        预定订单初始化、解析用户信息以及坐席信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.5" data-path="files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.5.</b>
                        
                        构造时间参数以及下单购票
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.6" data-path="files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.6.</b>
                        
                        测试运行以及完整代码
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="files/10-项目-国家企业公示网（selenium）/index.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        项目：国家企业公示网（selenium）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="10.1" data-path="files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.1.</b>
                        
                        项目分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.2.</b>
                        
                        webapi实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.3.</b>
                        
                        node_server节点任务调度
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.4.</b>
                        
                        crawler爬虫抓取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.5.</b>
                        
                        运行效果
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="11" data-path="files/duanzi/duanzi.html">
            
                
                    <a href="../../files/duanzi/duanzi.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        课余段子
                    </a>
            
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >Python爬虫课程讲义</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="scrapy&#x7684;&#x5165;&#x95E8;&#x4F7F;&#x7528;">scrapy&#x7684;&#x5165;&#x95E8;&#x4F7F;&#x7528;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;">&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;</h5>
<ul>
<li>&#x5E94;&#x7528; &#x521B;&#x5EFA;scrapy&#x7684;&#x9879;&#x76EE;</li>
<li>&#x5E94;&#x7528; &#x521B;&#x5EFA;scrapy&#x722C;&#x866B;</li>
<li>&#x5E94;&#x7528; &#x8FD0;&#x884C;scrapy&#x722C;&#x866B;</li>
<li>&#x5E94;&#x7528; scrapy&#x5B9A;&#x4F4D;&#x4EE5;&#x53CA;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x6216;&#x5C5E;&#x6027;&#x503C;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x638C;&#x63E1; response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;</li>
</ul>
<hr>
<h3 id="1-&#x8FD0;&#x884C;&#x793A;&#x4F8B;&#x4EE3;&#x7801;">1. &#x8FD0;&#x884C;&#x793A;&#x4F8B;&#x4EE3;&#x7801;</h3>
<blockquote>
<p>&#x9996;&#x5148;&#x6211;&#x4EEC;&#x6765;&#x770B;scrapy&#x722C;&#x866B;&#x8FD0;&#x884C;&#x7684;&#x6548;&#x679C;&#xFF0C;&#x770B;&#x5B8C;&#x8FD0;&#x884C;&#x6548;&#x679C;&#x4E4B;&#x540E;&#x6211;&#x4EEC;&#x5C31;&#x6765;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x4F7F;&#x7528;scrapy&#x6846;&#x67B6;&#x5199;&#x722C;&#x866B;</p>
</blockquote>
<ul>
<li>&#x8981;&#x5B8C;&#x6210;scrapy&#x722C;&#x866B;&#x9700;&#x8981;&#x5B9E;&#x73B0;&#x4EE5;&#x4E0B;&#x56DB;&#x4E2A;&#x6B65;&#x9AA4;&#xFF1A;<ol>
<li>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;scrapy&#x9879;&#x76EE;:scrapy startproject mySpider</li>
<li>&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x722C;&#x866B;:scrapy genspider itcast &quot;itcast.cn</li>
<li>&#x63D0;&#x53D6;&#x6570;&#x636E;:&#x5B8C;&#x5584;spider&#xFF0C;&#x4F7F;&#x7528;xpath&#x7B49;&#x65B9;&#x6CD5;</li>
<li>&#x4FDD;&#x5B58;&#x6570;&#x636E;:pipeline&#x4E2D;&#x4FDD;&#x5B58;&#x6570;&#x636E;</li>
</ol>
</li>
</ul>
<h3 id="2-&#x521B;&#x5EFA;scrapy&#x9879;&#x76EE;">2. &#x521B;&#x5EFA;scrapy&#x9879;&#x76EE;</h3>
<blockquote>
<p>&#x4E0B;&#x9762;&#x4EE5;&#x6293;&#x53D6;&#x4F20;&#x667A;&#x5E08;&#x8D44;&#x5E93;&#x6765;&#x5B66;&#x4E60;scrapy&#x7684;&#x5165;&#x95E8;&#x4F7F;&#x7528;&#xFF1A;<a href="http://www.itcast.cn/channel/teacher.shtml" target="_blank">http://www.itcast.cn/channel/teacher.shtml</a></p>
</blockquote>
<ul>
<li><p>scrapy&#x662F;&#x4E00;&#x4E2A;&#x7B2C;&#x4E09;&#x65B9;&#x5305;&#x9700;&#x8981;&#x989D;&#x5916;&#x5B89;&#x88C5;&#xFF1A;<code>pip install scrapy</code></p>
</li>
<li><p>&#x521B;&#x5EFA;scrapy&#x9879;&#x76EE;&#x7684;&#x547D;&#x4EE4;&#xFF1A;<code>scrapy startproject +&lt;&#x9879;&#x76EE;&#x540D;&#x5B57;&gt;</code></p>
</li>
<li><p>&#x793A;&#x4F8B;&#xFF1A;<code>scrapy startproject myspider</code></p>
</li>
<li><p>&#x751F;&#x6210;&#x7684;&#x76EE;&#x5F55;&#x548C;&#x6587;&#x4EF6;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#xFF1A;</p>
</li>
</ul>
<p><img src="images/2.1.scrapy&#x5165;&#x95E8;&#x4F7F;&#x7528;-1.png" width="60%"> </p>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528;-&#x521B;&#x5EFA;scrapy&#x7684;&#x9879;&#x76EE;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528; &#x521B;&#x5EFA;scrapy&#x7684;&#x9879;&#x76EE;</h5>
<hr>
<h3 id="3-&#x521B;&#x5EFA;&#x722C;&#x866B;">3. &#x521B;&#x5EFA;&#x722C;&#x866B;</h3>
<ul>
<li><p>&#x521B;&#x5EFA;&#x722C;&#x866B;&#x7684;&#x547D;&#x4EE4;</p>
<ul>
<li><strong>&#x5728;&#x9879;&#x76EE;&#x8DEF;&#x5F84;&#x4E0B;&#x6267;&#x884C;</strong>&#xFF1A;<code>scrapy genspider +&lt;&#x722C;&#x866B;&#x540D;&#x5B57;&gt; + &lt;&#x5141;&#x8BB8;&#x722C;&#x53D6;&#x7684;&#x57DF;&#x540D;&gt;</code></li>
</ul>
</li>
<li><p>&#x793A;&#x4F8B;&#xFF1A;</p>
</li>
</ul>
<pre><code>cd myspider
scrapy genspider itcast itcast.cn
</code></pre><ul>
<li>&#x751F;&#x6210;&#x7684;&#x76EE;&#x5F55;&#x548C;&#x6587;&#x4EF6;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#xFF1A;</li>
</ul>
<p><img src="images/2.2.scrapy&#x5165;&#x95E8;&#x4F7F;&#x7528;-2.png" width="60%"></p>
<ul>
<li><strong>&#x751F;&#x6210;&#x7684;&#x722C;&#x866B;&#x7C7B;&#x603B;&#x7ED3;</strong>&#xFF1A;<ul>
<li>&#x722C;&#x866B;&#x7C7B;&#x7EE7;&#x627F;&#x4E86;scrapy.Spider&#x7236;&#x7C7B;</li>
<li>name&#x5C5E;&#x6027;&#x662F;&#x722C;&#x866B;&#x540D;</li>
<li>start_url&#x89C4;&#x5B9A;&#x8D77;&#x59CB;&#x7684;url&#xFF0C;&#x53EF;&#x4EE5;&#x591A;&#x4E2A;</li>
<li>allowed_domains&#x89C4;&#x5B9A;&#x722C;&#x53D6;&#x8303;&#x56F4;&#x7684;&#x57DF;&#x540D;&#xFF0C;&#x53EF;&#x4EE5;&#x591A;&#x4E2A;<ul>
<li>&#x8D77;&#x59CB;url&#x4E0D;&#x53D7;&#x6B64;&#x9650;&#x5236;</li>
<li>&#x5728;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x63D0;&#x53D6;&#x7684;url&#x5730;&#x5740;&#x5982;&#x679C;&#x8981;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#xFF0C;&#x5219;&#x5FC5;&#x987B;&#x5C5E;&#x4E8E;allowed_domains&#x8303;&#x56F4;&#x5185;</li>
<li>&#x6211;&#x4EEC;&#x4F1A;&#x5728;&#x540E;&#x7EED;&#x7684;&#x8BFE;&#x7A0B;&#x4E2D;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x5728;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x6784;&#x9020;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#xFF0C;&#x8FD9;&#x91CC;&#x4E0D;&#x505A;&#x5C55;&#x5F00;</li>
</ul>
</li>
<li>scrapy.Spider&#x722C;&#x866B;&#x7C7B;&#x4E2D;&#x5FC5;&#x987B;&#x6709;&#x540D;&#x4E3A;parse&#x7684;&#x89E3;&#x6790;</li>
<li>&#x4E5F;&#x53EF;&#x4EE5;&#x81EA;&#x5B9A;&#x4E49;&#x5176;&#x4ED6;&#x89E3;&#x6790;&#x51FD;&#x6570;</li>
<li>&#x542F;&#x52A8;&#x722C;&#x866B;&#x7684;&#x65F6;&#x5019;&#x6CE8;&#x610F;&#x542F;&#x52A8;&#x7684;&#x4F4D;&#x7F6E;&#xFF0C;&#x662F;&#x5728;&#x9879;&#x76EE;&#x8DEF;&#x5F84;&#x4E0B;&#x542F;&#x52A8;</li>
</ul>
</li>
</ul>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528;-&#x521B;&#x5EFA;scrapy&#x722C;&#x866B;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528; &#x521B;&#x5EFA;scrapy&#x722C;&#x866B;</h5>
<hr>
<h3 id="4-&#x5B8C;&#x5584;spider">4. &#x5B8C;&#x5584;spider</h3>
<blockquote>
<p>&#x5B8C;&#x5584;spider&#x5373;&#x901A;&#x8FC7;&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x6570;&#x636E;&#x7684;&#x63D0;&#x53D6;&#x7B49;&#x64CD;&#x4F5C;</p>
</blockquote>
<h4 id="41-&#x9875;&#x9762;&#x5206;&#x6790;">4.1 &#x9875;&#x9762;&#x5206;&#x6790;</h4>
<blockquote>
<p>&#x5728;&#x5B8C;&#x6210;&#x4EE3;&#x7801;&#x4E4B;&#x524D;&#xFF0C;&#x9996;&#x5148;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5206;&#x6790;<a href="http://www.itcast.cn/channel/teacher.shtml" target="_blank">itcast&#x5E08;&#x8D44;&#x5E93;&#x9875;&#x9762;</a></p>
</blockquote>
<ul>
<li>&#x786E;&#x5B9A;url&#x5730;&#x5740;</li>
<li>&#x786E;&#x5B9A;&#x6570;&#x636E;&#x6240;&#x5728;&#x4F4D;&#x7F6E;</li>
</ul>
<h4 id="42-&#x5728;myspidermyspiderspidersitcastpy&#x4E2D;&#x4FEE;&#x6539;&#x5185;&#x5BB9;&#x5982;&#x4E0B;">4.2 &#x5728;/myspider/myspider/spiders/itcast.py&#x4E2D;&#x4FEE;&#x6539;&#x5185;&#x5BB9;&#x5982;&#x4E0B;:</h4>
<pre><code>import scrapy

class ItcastSpider(scrapy.Spider):  # &#x7EE7;&#x627F;scrapy.spider
    # &#x722C;&#x866B;&#x540D;&#x5B57; 
    name = &apos;itcast&apos; 
    # &#x5141;&#x8BB8;&#x722C;&#x53D6;&#x7684;&#x8303;&#x56F4;
    allowed_domains = [&apos;itcast.cn&apos;] 
    # &#x5F00;&#x59CB;&#x722C;&#x53D6;&#x7684;url&#x5730;&#x5740;
    start_urls = [&apos;http://www.itcast.cn/channel/teacher.shtml&apos;]

    # &#x6570;&#x636E;&#x63D0;&#x53D6;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x63A5;&#x53D7;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x4F20;&#x8FC7;&#x6765;&#x7684;response
    def parse(self, response): 
        # scrapy&#x7684;response&#x5BF9;&#x8C61;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x8FDB;&#x884C;xpath
        names = response.xpath(&apos;//div[@class=&quot;tea_con&quot;]//li/div/h3/text()&apos;) 
        print(names)

        # &#x83B7;&#x53D6;&#x5177;&#x4F53;&#x6570;&#x636E;&#x6587;&#x672C;&#x7684;&#x65B9;&#x5F0F;&#x5982;&#x4E0B;
        # &#x5206;&#x7EC4;
        li_list = response.xpath(&apos;//div[@class=&quot;tea_con&quot;]//li&apos;) 
        for li in li_list:
            # &#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x5B57;&#x5178;
            item = {}
            # &#x5229;&#x7528;scrapy&#x5C01;&#x88C5;&#x597D;&#x7684;xpath&#x9009;&#x62E9;&#x5668;&#x5B9A;&#x4F4D;&#x5143;&#x7D20;&#xFF0C;&#x5E76;&#x901A;&#x8FC7;extract()&#x6216;extract_first()&#x6765;&#x83B7;&#x53D6;&#x7ED3;&#x679C;
            item[&apos;name&apos;] = li.xpath(&apos;.//h3/text()&apos;).extract_first() # &#x8001;&#x5E08;&#x7684;&#x540D;&#x5B57;
            item[&apos;level&apos;] = li.xpath(&apos;.//h4/text()&apos;).extract_first() # &#x8001;&#x5E08;&#x7684;&#x7EA7;&#x522B;
            item[&apos;text&apos;] = li.xpath(&apos;.//p/text()&apos;).extract_first() # &#x8001;&#x5E08;&#x7684;&#x4ECB;&#x7ECD;
            print(item)
</code></pre><h4 id="43-&#x8FD0;&#x884C;&#x722C;&#x866B;">4.3 &#x8FD0;&#x884C;&#x722C;&#x866B;</h4>
<ul>
<li><p>&#x547D;&#x4EE4;&#xFF1A;&#x5728;&#x9879;&#x76EE;&#x76EE;&#x5F55;&#x4E0B;&#x6267;&#x884C;<code>scrapy crawl +&lt;&#x722C;&#x866B;&#x540D;&#x5B57;&gt;</code></p>
</li>
<li><p>&#x793A;&#x4F8B;&#xFF1A;<code>scrapy crawl itcast</code></p>
</li>
</ul>
<h3 id="5-&#x5B9A;&#x4F4D;&#x5143;&#x7D20;&#x4EE5;&#x53CA;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x3001;&#x5C5E;&#x6027;&#x503C;&#x7684;&#x65B9;&#x6CD5;">5. &#x5B9A;&#x4F4D;&#x5143;&#x7D20;&#x4EE5;&#x53CA;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x3001;&#x5C5E;&#x6027;&#x503C;&#x7684;&#x65B9;&#x6CD5;</h3>
<blockquote>
<p>&#x89E3;&#x6790;&#x5E76;&#x83B7;&#x53D6;scrapy&#x722C;&#x866B;&#x4E2D;&#x7684;&#x6570;&#x636E;: &#x5229;&#x7528;xpath&#x89C4;&#x5219;&#x5B57;&#x7B26;&#x4E32;&#x8FDB;&#x884C;&#x5B9A;&#x4F4D;&#x548C;&#x63D0;&#x53D6;</p>
</blockquote>
<ol>
<li>response.xpath&#x65B9;&#x6CD5;&#x7684;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x662F;&#x4E00;&#x4E2A;&#x7C7B;&#x4F3C;list&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x5176;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x662F;selector&#x5BF9;&#x8C61;&#xFF0C;&#x64CD;&#x4F5C;&#x548C;&#x5217;&#x8868;&#x4E00;&#x6837;&#xFF0C;&#x4F46;&#x662F;&#x6709;&#x4E00;&#x4E9B;&#x989D;&#x5916;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x989D;&#x5916;&#x65B9;&#x6CD5;extract()&#xFF1A;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x6709;&#x5B57;&#x7B26;&#x4E32;&#x7684;&#x5217;&#x8868;</li>
<li>&#x989D;&#x5916;&#x65B9;&#x6CD5;extract_first()&#xFF1A;&#x8FD4;&#x56DE;&#x5217;&#x8868;&#x4E2D;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5217;&#x8868;&#x4E3A;&#x7A7A;&#x6CA1;&#x6709;&#x8FD4;&#x56DE;None</li>
</ol>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528;-scrapy&#x5B9A;&#x4F4D;&#x4EE5;&#x53CA;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x6216;&#x5C5E;&#x6027;&#x503C;&#x7684;&#x65B9;&#x6CD5;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528; scrapy&#x5B9A;&#x4F4D;&#x4EE5;&#x53CA;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x6216;&#x5C5E;&#x6027;&#x503C;&#x7684;&#x65B9;&#x6CD5;</h5>
<hr>
<h3 id="6-response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;">6. response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;</h3>
<blockquote>
<p>response&#x5BF9;&#x8C61;&#x9664;&#x4E86;&#x5177;&#x6709;xpath&#x51FD;&#x6570;&#x4EE5;&#x5916;&#x8FD8;&#x6709;&#x4E00;&#x4E9B;&#x5E38;&#x7528;&#x7684;&#x5C5E;&#x6027;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;</p>
</blockquote>
<ul>
<li>response.url&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x7684;url&#x5730;&#x5740;</li>
<li>response.request.url&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x5BF9;&#x5E94;&#x7684;&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;</li>
<li>response.headers&#xFF1A;&#x54CD;&#x5E94;&#x5934;</li>
<li>response.requests.headers&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x7684;&#x8BF7;&#x6C42;&#x5934;</li>
<li>response.body&#xFF1A;&#x54CD;&#x5E94;&#x4F53;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;html&#x4EE3;&#x7801;&#xFF0C;byte&#x7C7B;&#x578B;</li>
<li>response.status&#xFF1A;&#x54CD;&#x5E94;&#x72B6;&#x6001;&#x7801;</li>
</ul>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1;-response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1; response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;</h5>
<hr>
<h3 id="7-&#x7BA1;&#x9053;&#x7684;&#x7B80;&#x5355;&#x4F7F;&#x7528;">7. &#x7BA1;&#x9053;&#x7684;&#x7B80;&#x5355;&#x4F7F;&#x7528;</h3>
<blockquote>
<p>&#x5229;&#x7528;&#x7BA1;&#x9053;pipeline&#x6765;&#x5904;&#x7406;(&#x4FDD;&#x5B58;)&#x6570;&#x636E;</p>
</blockquote>
<h4 id="71-&#x5BF9;itcast&#x722C;&#x866B;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x5B8C;&#x5584;">7.1 &#x5BF9;itcast&#x722C;&#x866B;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x5B8C;&#x5584;</h4>
<p>&#x5728;&#x722C;&#x866B;&#x6587;&#x4EF6;itcast.py&#x4E2D;parse()&#x51FD;&#x6570;&#x4E2D;&#x6700;&#x540E;&#x6DFB;&#x52A0;</p>
<pre><code>yield item
</code></pre><h5 id="&#x601D;&#x8003;&#xFF1A;&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x4F7F;&#x7528;yield&#xFF1F;">&#x601D;&#x8003;&#xFF1A;&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x4F7F;&#x7528;yield&#xFF1F;</h5>
<p>&#x8BA9;&#x6574;&#x4E2A;&#x51FD;&#x6570;&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x751F;&#x6210;&#x5668;</p>
<ul>
<li>&#x904D;&#x5386;&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x8FD4;&#x56DE;&#x503C;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x6328;&#x4E2A;&#x628A;&#x6570;&#x636E;&#x8BFB;&#x5230;&#x5185;&#x5B58;&#xFF0C;&#x4E0D;&#x4F1A;&#x9020;&#x6210;&#x5185;&#x5B58;&#x7684;&#x77AC;&#x95F4;&#x5360;&#x7528;&#x8FC7;&#x9AD8;&#xFF0C;python3&#x4E2D;&#x7684;range&#x548C;python2&#x4E2D;&#x7684;xrange&#x540C;&#x7406;</li>
</ul>
<p><strong>&#x6CE8;&#x610F;&#xFF1A;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x7684;yield&#x80FD;&#x591F;&#x4F20;&#x9012;&#x7684;&#x5BF9;&#x8C61;&#x53EA;&#x80FD;&#x662F;&#xFF1A;BaseItem, Request, dict, None</strong></p>
<h4 id="72-&#x4FEE;&#x6539;pipelinespy&#x6587;&#x4EF6;">7.2 &#x4FEE;&#x6539;pipelines.py&#x6587;&#x4EF6;</h4>
<pre><code>import json

class ItcastPipeline():
    # &#x722C;&#x866B;&#x6587;&#x4EF6;&#x4E2D;&#x63D0;&#x53D6;&#x6570;&#x636E;&#x7684;&#x65B9;&#x6CD5;&#x6BCF;yield&#x4E00;&#x6B21;item&#xFF0C;&#x5C31;&#x4F1A;&#x8FD0;&#x884C;&#x4E00;&#x6B21;
    # &#x8BE5;&#x65B9;&#x6CD5;&#x4E3A;&#x56FA;&#x5B9A;&#x540D;&#x79F0;&#x51FD;&#x6570;
    def process_item(self, item, spider):
        print(item)
</code></pre><h4 id="73-&#x5728;settingspy&#x8BBE;&#x7F6E;&#x5F00;&#x542F;pipeline">7.3 &#x5728;settings.py&#x8BBE;&#x7F6E;&#x5F00;&#x542F;pipeline</h4>
<pre><code>ITEM_PIPELINES = {
    &apos;myspider.pipelines.ItcastPipeline&apos;: 400
}
</code></pre><hr>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<ol>
<li>scrapy&#x7684;&#x5B89;&#x88C5;&#xFF1A;pip install scrapy</li>
<li>&#x521B;&#x5EFA;scrapy&#x7684;&#x9879;&#x76EE;: scrapy startproject myspider</li>
<li>&#x521B;&#x5EFA;scrapy&#x722C;&#x866B;&#xFF1A;&#x5728;&#x9879;&#x76EE;&#x76EE;&#x5F55;&#x4E0B;&#x6267;&#x884C; scrapy genspider itcast itcast.cn</li>
<li>&#x8FD0;&#x884C;scrapy&#x722C;&#x866B;&#xFF1A;&#x5728;&#x9879;&#x76EE;&#x76EE;&#x5F55;&#x4E0B;&#x6267;&#x884C; scrapy crawl itcast</li>
<li>&#x89E3;&#x6790;&#x5E76;&#x83B7;&#x53D6;scrapy&#x722C;&#x866B;&#x4E2D;&#x7684;&#x6570;&#x636E;&#xFF1A;<ol>
<li>response.xpath&#x65B9;&#x6CD5;&#x7684;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x662F;&#x4E00;&#x4E2A;&#x7C7B;&#x4F3C;list&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x5176;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x662F;selector&#x5BF9;&#x8C61;&#xFF0C;&#x64CD;&#x4F5C;&#x548C;&#x5217;&#x8868;&#x4E00;&#x6837;&#xFF0C;&#x4F46;&#x662F;&#x6709;&#x4E00;&#x4E9B;&#x989D;&#x5916;&#x7684;&#x65B9;&#x6CD5;</li>
<li>extract() &#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x6709;&#x5B57;&#x7B26;&#x4E32;&#x7684;&#x5217;&#x8868;</li>
<li>extract_first() &#x8FD4;&#x56DE;&#x5217;&#x8868;&#x4E2D;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5217;&#x8868;&#x4E3A;&#x7A7A;&#x6CA1;&#x6709;&#x8FD4;&#x56DE;None</li>
</ol>
</li>
<li>scrapy&#x7BA1;&#x9053;&#x7684;&#x57FA;&#x672C;&#x4F7F;&#x7528;:<ol>
<li>&#x5B8C;&#x5584;pipelines.py&#x4E2D;&#x7684;process_item&#x51FD;&#x6570;</li>
<li>&#x5728;settings.py&#x4E2D;&#x8BBE;&#x7F6E;&#x5F00;&#x542F;pipeline</li>
</ol>
</li>
<li>response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#x7684;&#x5E38;&#x7528;&#x5C5E;&#x6027;<ol>
<li>response.url&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x7684;url&#x5730;&#x5740;</li>
<li>response.request.url&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x5BF9;&#x5E94;&#x7684;&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;</li>
<li>response.headers&#xFF1A;&#x54CD;&#x5E94;&#x5934;</li>
<li>response.requests.headers&#xFF1A;&#x5F53;&#x524D;&#x54CD;&#x5E94;&#x7684;&#x8BF7;&#x6C42;&#x5934;</li>
<li>response.body&#xFF1A;&#x54CD;&#x5E94;&#x4F53;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;html&#x4EE3;&#x7801;&#xFF0C;byte&#x7C7B;&#x578B;</li>
<li>response.status&#xFF1A;&#x54CD;&#x5E94;&#x72B6;&#x6001;&#x7801;</li>
</ol>
</li>
</ol>
<hr>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; ITCast all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x300C;Revision Time:
2019-02-27 20:33:50&#x300D;
</span></footer>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html" class="navigation navigation-prev " aria-label="Previous page: scrapy的概念作用和工作流程"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html" class="navigation navigation-next " aria-label="Next page: scrapy构造并发送请求"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"disqus":{"shortName":"gitbookuse"},"github":{"url":"https://github.com/dododream"},"search-pro":{"cutWordLib":"nodejieba","defineWord":["gitbook-use"]},"sharing":{"weibo":true,"facebook":true,"twitter":true,"google":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"tbfed-pagefooter":{"copyright":"Copyright © ITCast","modify_label":"「Revision Time:","modify_format":"YYYY-MM-DD HH:mm:ss」"},"baidu":{"token":"ff100361cdce95dd4c8fb96b4009f7bc"},"sitemap":{"hostname":"http://www.treenewbee.top"},"donate":{"wechat":"http://weixin.png","alipay":"http://alipay.png","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"edit-link":{"base":"https://github.com/dododream/edit","label":"Edit This Page"},"splitter":{},"toggle-chapters":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
    </body>
    <!-- End of book Python爬虫课程讲义 -->
</html>
