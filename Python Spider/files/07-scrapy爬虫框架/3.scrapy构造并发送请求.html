<!DOCTYPE HTML>
<html lang="en" >
    <!-- Start book Python爬虫课程讲义 -->
    <head>
        <!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy构造并发送请求 | Python爬虫课程讲义</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        <meta name="author" content="BigCat">
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-tbfed-pagefooter/footer.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html" />
    
    
    <link rel="prev" href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html" />
    

        <!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
        
    <div class="book"
        data-level="7.3"
        data-chapter-title="scrapy构造并发送请求"
        data-filepath="files/07-scrapy爬虫框架/3.scrapy构造并发送请求.md"
        data-basepath="../.."
        data-revision="Thu Feb 28 2019 03:09:16 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        传智播客Python学科爬虫课件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="files/01-爬虫基础/index.html">
            
                
                    <a href="../../files/01-爬虫基础/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        网络爬虫知识基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="files/01-爬虫基础/1.爬虫概述.html">
            
                
                    <a href="../../files/01-爬虫基础/1.爬虫概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫概述与分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
            
                
                    <a href="../../files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        (了解) 通用爬虫和聚焦爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="files/01-爬虫基础/3.爬虫基础知识.html">
            
                
                    <a href="../../files/01-爬虫基础/3.爬虫基础知识.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        爬虫基础知识
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="files/01-爬虫基础/4.http协议复习.html">
            
                
                    <a href="../../files/01-爬虫基础/4.http协议复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        (复习) http协议复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="files/02-requests模块/index.html">
            
                
                    <a href="../../files/02-requests模块/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        HTTP请求处理工具：requests
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="files/02-requests模块/requests模块1.html">
            
                
                    <a href="../../files/02-requests模块/requests模块1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        requests模块处理的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="files/02-requests模块/requests模块2.html">
            
                
                    <a href="../../files/02-requests模块/requests模块2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        requests模块处理Cookie和Proxy高级功能
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="files/02-requests模块/requests模块3.html">
            
                
                    <a href="../../files/02-requests模块/requests模块3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        requests模块处理post请求与session会话保持
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="files/03-数据提取/index.html">
            
                
                    <a href="../../files/03-数据提取/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        HTTP数据提取工具：jsonpath 和 lxml/xpath
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="files/03-数据提取/1.数据提取概述.html">
            
                
                    <a href="../../files/03-数据提取/1.数据提取概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        数据提取概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="files/03-数据提取/2.数据提取-jsonpath模块.html">
            
                
                    <a href="../../files/03-数据提取/2.数据提取-jsonpath模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        数据提取-jsonpath模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="files/03-数据提取/3.数据提取-lxml模块.html">
            
                
                    <a href="../../files/03-数据提取/3.数据提取-lxml模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        数据提取-lxml模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="files/04-selenium的使用/index.html">
            
                
                    <a href="../../files/04-selenium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        web自动化测试工具：selenium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="files/04-selenium的使用/1.selenium的介绍.html">
            
                
                    <a href="../../files/04-selenium的使用/1.selenium的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        selenium的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
            
                
                    <a href="../../files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium定位获取标签对象并提取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="files/04-selenium的使用/3.selenium的其它使用方法.html">
            
                
                    <a href="../../files/04-selenium的使用/3.selenium的其它使用方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        selenium的其它使用方法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="files/05-抓包、反爬与反爬解决方案/index.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        抓包、反爬与反爬解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        常见的反爬手段、原理以及应对思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        打码平台处理验证码
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        chrome浏览器的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        js2py模块的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.5" data-path="files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        cookie池和代理池
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="files/06-mongodb数据库/index.html">
            
                
                    <a href="../../files/06-mongodb数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        MongoDB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="files/06-mongodb数据库/1.mongodb介绍和安装.html">
            
                
                    <a href="../../files/06-mongodb数据库/1.mongodb介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        mongodb介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="files/06-mongodb数据库/2.mongodb的简单使用.html">
            
                
                    <a href="../../files/06-mongodb数据库/2.mongodb的简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        mongodb的简单使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="files/06-mongodb数据库/3.mongodb的增删改查.html">
            
                
                    <a href="../../files/06-mongodb数据库/3.mongodb的增删改查.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        mongodb的增删改查
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="files/06-mongodb数据库/4.mongodb的索引操作.html">
            
                
                    <a href="../../files/06-mongodb数据库/4.mongodb的索引操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.4.</b>
                        
                        mongodb的索引操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="files/06-mongodb数据库/5.mongodb的权限管理.html">
            
                
                    <a href="../../files/06-mongodb数据库/5.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.5.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.6" data-path="files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
            
                
                    <a href="../../files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.6.</b>
                        
                        mongodb和python交互（pymongo模块的使用）
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="files/07-scrapy爬虫框架/index.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Scrapy爬虫框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7.3" data-path="files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.3.</b>
                        
                        scrapy构造并发送请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.4.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.6.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.7" data-path="files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.7.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.8" data-path="files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.8.</b>
                        
                        scrapy_redis原理分析并实现断点续爬以及分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.9" data-path="files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.9.</b>
                        
                        scrapy_splash组件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.10" data-path="files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.10.</b>
                        
                        scrapy的日志信息与配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.11" data-path="files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.11.</b>
                        
                        scrapyd部署scrapy项目
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="files/08-appium的使用/index.html">
            
                
                    <a href="../../files/08-appium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        移动端APP自动化测试工具：appium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="files/08-appium的使用/1.appium环境安装.html">
            
                
                    <a href="../../files/08-appium的使用/1.appium环境安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        appium环境安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
            
                
                    <a href="../../files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        利用appium自动控制移动设备并提取数据
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="files/09-项目-12306购票（requests）/index.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        项目：12306购票（requests）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        12306购票抓包分析以及任务分解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        处理验证码并完成登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.3" data-path="files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.3.</b>
                        
                        解析车站信息以及车辆信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.4" data-path="files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.4.</b>
                        
                        预定订单初始化、解析用户信息以及坐席信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.5" data-path="files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.5.</b>
                        
                        构造时间参数以及下单购票
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.6" data-path="files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.6.</b>
                        
                        测试运行以及完整代码
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="files/10-项目-国家企业公示网（selenium）/index.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        项目：国家企业公示网（selenium）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="10.1" data-path="files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.1.</b>
                        
                        项目分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.2.</b>
                        
                        webapi实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.3.</b>
                        
                        node_server节点任务调度
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.4.</b>
                        
                        crawler爬虫抓取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.5.</b>
                        
                        运行效果
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="11" data-path="files/duanzi/duanzi.html">
            
                
                    <a href="../../files/duanzi/duanzi.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        课余段子
                    </a>
            
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >Python爬虫课程讲义</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="scrapy&#x6784;&#x9020;&#x5E76;&#x53D1;&#x9001;&#x8BF7;&#x6C42;">scrapy&#x6784;&#x9020;&#x5E76;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;">&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;</h5>
<ul>
<li>&#x5E94;&#x7528; &#x6784;&#x9020;Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</li>
<li>&#x5E94;&#x7528; &#x5229;&#x7528;meta&#x53C2;&#x6570;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#x6570;&#x636E;</li>
</ul>
<hr>
<h3 id="1-&#x7FFB;&#x9875;&#x8BF7;&#x6C42;&#x7684;&#x601D;&#x8DEF;">1. &#x7FFB;&#x9875;&#x8BF7;&#x6C42;&#x7684;&#x601D;&#x8DEF;</h3>
<blockquote>
<p>&#x8FD0;&#x884C;&#x6700;&#x7EC8;&#x4EE3;&#x7801;&#xFF0C;&#x67E5;&#x770B;<a href="http://hr.tencent.com/position.php" target="_blank">&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x7F51;&#x7AD9;</a>&#xFF1A;&#x793A;&#x4F8B;&#x4EE3;&#x7801;&#x6210;&#x529F;&#x80FD;&#x591F;&#x7FFB;&#x9875;&#x83B7;&#x53D6;&#x5176;&#x5B83;&#x9875;&#x4E2D;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x8FD9;&#x662F;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x7684;&#x5462;&#xFF1F;</p>
</blockquote>
<p><img src="images/3.1.scrapy&#x7FFB;&#x9875;.png" width="100%"> </p>
<h4 id="11-&#x9996;&#x5148;&#x56DE;&#x987E;requests&#x6A21;&#x5757;&#x662F;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#x8BF7;&#x6C42;&#x7684;&#xFF1A;">1.1 &#x9996;&#x5148;&#x56DE;&#x987E;requests&#x6A21;&#x5757;&#x662F;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#x8BF7;&#x6C42;&#x7684;&#xFF1A;</h4>
<ol>
<li>&#x627E;&#x5230;&#x4E0B;&#x4E00;&#x9875;&#x7684;URL&#x5730;&#x5740;</li>
<li>&#x8C03;&#x7528;requests.get(url)</li>
</ol>
<h4 id="12-scrapy&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#x7684;&#x601D;&#x8DEF;&#xFF1A;">1.2 scrapy&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#x7684;&#x601D;&#x8DEF;&#xFF1A;</h4>
<ol>
<li>&#x627E;&#x5230;&#x4E0B;&#x4E00;&#x9875;&#x7684;url&#x5730;&#x5740;</li>
<li>&#x6784;&#x9020;url&#x5730;&#x5740;&#x7684;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x4F20;&#x9012;&#x7ED9;&#x5F15;&#x64CE;</li>
</ol>
<h3 id="2-scrapy&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7684;&#x65B9;&#x6CD5;">2. scrapy&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7684;&#x65B9;&#x6CD5;</h3>
<blockquote>
<p>&#x8981;&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#xFF0C;&#x5C31;&#x9700;&#x8981;&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x5C31;&#x6765;&#x5B66;&#x4E60;scrapy&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7684;&#x65B9;&#x6CD5;</p>
</blockquote>
<ol>
<li>&#x786E;&#x5B9A;url&#x5730;&#x5740;</li>
<li>&#x6784;&#x9020;&#x8BF7;&#x6C42;&#xFF1A;<code>scrapy.Request(url, callback)</code><ul>
<li><code>callback</code>&#x53C2;&#x6570;&#xFF1A;&#x6307;&#x5B9A;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x540D;&#x79F0;&#xFF0C;&#x8868;&#x793A;&#x8BE5;&#x8BF7;&#x6C42;&#x8FD4;&#x56DE;&#x7684;&#x54CD;&#x5E94;&#x4F7F;&#x7528;&#x54EA;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x89E3;&#x6790;</li>
</ul>
</li>
<li>&#x628A;&#x8BF7;&#x6C42;&#x4EA4;&#x7ED9;&#x5F15;&#x64CE;&#xFF1A;<code>yield scrapy.Request(url, callback)</code></li>
</ol>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528;-&#x6784;&#x9020;request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x53D1;&#x9001;&#x8BF7;&#x6C42;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528; &#x6784;&#x9020;Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</h5>
<hr>
<h3 id="3-&#x5206;&#x6790;&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x601D;&#x8DEF;">3. &#x5206;&#x6790;&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x601D;&#x8DEF;</h3>
<blockquote>
<p>&#x63A5;&#x4E0B;&#x6765;&#x6211;&#x4EEC;&#x5C31;&#x901A;&#x8FC7;&#x722C;&#x53D6;<a href="http://hr.tencent.com/position.php" target="_blank">&#x817E;&#x8BAF;&#x62DB;&#x8058;</a>&#x7684;&#x9875;&#x9762;&#x7684;&#x62DB;&#x8058;&#x4FE1;&#x606F;&#x5E76;&#x5B9E;&#x73B0;&#x7FFB;&#x9875;&#xFF0C;&#x6765;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x9996;&#x5148;&#x6765;&#x5206;&#x6790;&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x7F51;&#x7AD9;&#xFF1A;</p>
</blockquote>
<ol>
<li><p>&#x786E;&#x5B9A;&#x8D77;&#x59CB;url</p>
<ul>
<li><code>https://hr.tencent.com/position.php</code></li>
</ul>
</li>
<li><p>&#x786E;&#x5B9A;&#x722C;&#x53D6;&#x8303;&#x56F4;&#x7684;&#x57DF;&#x540D;</p>
<ul>
<li><code>allowed_domains = [&apos;hr.tencent.com&apos;]</code></li>
</ul>
</li>
<li><p>&#x786E;&#x5B9A;&#x6570;&#x636E;&#x6240;&#x5728;&#x4F4D;&#x7F6E;</p>
<p><img src="images/&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x786E;&#x5B9A;&#x6570;&#x636E;&#x548C;&#x4E0B;&#x4E00;&#x9875;.png" alt="&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x786E;&#x5B9A;&#x6570;&#x636E;&#x548C;&#x4E0B;&#x4E00;&#x9875;"></p>
</li>
<li><p>&#x786E;&#x5B9A;&#x4E0B;&#x4E00;&#x9875;&#x7684;url&#xFF0C;&#x4EE5;&#x53CA;&#x7EC4;&#x540E;&#x4E00;&#x9875;&#x7684;&#x60C5;&#x51B5;</p>
<p><img src="images/&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x6700;&#x540E;&#x4E00;&#x9875;&#x7684;&#x7FFB;&#x9875;&#x60C5;&#x51B5;.png" alt="&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x6700;&#x540E;&#x4E00;&#x9875;&#x7684;&#x7FFB;&#x9875;&#x60C5;&#x51B5;"></p>
</li>
</ol>
<h3 id="4-&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;">4. &#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;</h3>
<blockquote>
<p>&#x7ECF;&#x8FC7;&#x5206;&#x6790;&#x4E4B;&#x540E;&#x6211;&#x4EEC;&#x5C31;&#x6765;&#x5B9E;&#x73B0;&#x4EE3;&#x7801;</p>
</blockquote>
<h4 id="41-&#x722C;&#x866B;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;">4.1 &#x722C;&#x866B;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;</h4>
<ol>
<li>&#x521B;&#x5EFA;&#x9879;&#x76EE;<code>scrapy startproject Tencent</code></li>
<li>&#x5728;&#x9879;&#x76EE;&#x8DEF;&#x5F84;&#x4E0B;&#x521B;&#x5EFA;&#x722C;&#x866B;<code>scrapy genspider tencent xxx.com</code></li>
<li>&#x4FEE;&#x6539;<code>start_url = &apos;https://hr.tencent.com/position.php&apos;</code></li>
<li><p>&#x4FEE;&#x6539;<code>allowed_domains = [&apos;hr.tencent.com&apos;]</code></p>
</li>
<li><p>&#x5728;&#x722C;&#x866B;&#x6587;&#x4EF6;&#x7684;<code>parse</code>&#x51FD;&#x6570;&#x4E2D;&#x5206;&#x7EC4;&#x63D0;&#x53D6;&#x6570;&#x636E;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;</p>
<pre><code class="lang-python">    def parse(self, response):
        tr_list = response.xpath(&apos;//table[@class=&quot;tablelist&quot;]//tr)[1:-1] # &#x5206;&#x7EC4;
        for tr in tr_list:
            item = {}
            item[&apos;title&apos;] = tr.xpath(&apos;./td[1]/a/text()).extract_first() # &#x63D0;&#x53D6;&#x5E76;&#x7EC4;&#x88C5;&#x6570;&#x636E;
            yield item # &#x8FD4;&#x56DE;&#x6570;&#x636E;
</code></pre>
</li>
<li><p>&#x5728;&#x722C;&#x866B;&#x6587;&#x4EF6;&#x7684;<code>parse</code>&#x51FD;&#x6570;&#x4E2D;&#xFF0C;&#x63D0;&#x53D6;&#x4E0B;&#x4E00;&#x9875;&#x7684;url&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x6784;&#x9020;&#x7684;Request&#x5BF9;&#x8C61;</p>
<pre><code class="lang-python">......
        <span class="hljs-comment"># &#x63D0;&#x53D6;&#x4E0B;&#x4E00;&#x9875;&#x7684;href&#x5E76;&#x62FC;&#x63A5;url</span>
        next_url = <span class="hljs-string">&apos;https://hr.tencent.com/&apos;</span> + response.xpath(<span class="hljs-string">&apos;//a[text()=&quot;&#x4E0B;&#x4E00;&#x9875;&quot;]/@href&apos;</span>).extract_first()
        <span class="hljs-comment"># &#x5224;&#x65AD;&#x662F;&#x5426;&#x662F;&#x6700;&#x540E;&#x4E00;&#x9875;</span>
        <span class="hljs-keyword">if</span> response.xpath(<span class="hljs-string">&apos;//a[text()=&quot;&#x4E0B;&#x4E00;&#x9875;&quot;]/@href&apos;</span>).extract_first() != <span class="hljs-string">&apos;javascript:;&apos;</span>:
            <span class="hljs-comment"># &#x6784;&#x9020;scrapy.Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;yield&#x7ED9;&#x5F15;&#x64CE;</span>
            <span class="hljs-comment"># &#x5229;&#x7528;callback&#x53C2;&#x6570;&#x6307;&#x5B9A;&#x8BE5;Request&#x5BF9;&#x8C61;&#x4E4B;&#x540E;&#x83B7;&#x53D6;&#x7684;&#x54CD;&#x5E94;&#x7528;&#x54EA;&#x4E2A;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x89E3;&#x6790;</span>
            <span class="hljs-comment"># &#x6CE8;&#x610F;&#x8FD9;&#x91CC;&#x662F;yield</span>
            <span class="hljs-keyword">yield</span> scrapy.Request(next_url, callback=self.parse)
......
</code></pre>
</li>
</ol>
<h4 id="42-&#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x9879;">4.2 &#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x9879;</h4>
<ol>
<li><p>&#x53EF;&#x4EE5;&#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;User-Agent&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-comment"># scrapy&#x53D1;&#x9001;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;&#x7684;&#x9ED8;&#x8BA4;UA&#x90FD;&#x662F;&#x8BBE;&#x7F6E;&#x7684;&#x8FD9;&#x4E2A;User-Agent</span>
USER_AGENT = <span class="hljs-string">&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&apos;</span>
</code></pre>
</li>
<li><p>&#x53EF;&#x4EE5;&#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;ROBOTS&#x534F;&#x8BAE;</p>
<pre><code class="lang-python"><span class="hljs-comment"># False&#x8868;&#x793A;&#x5FFD;&#x7565;&#x7F51;&#x7AD9;&#x7684;robots.txt&#x534F;&#x8BAE;&#xFF0C;&#x9ED8;&#x8BA4;&#x4E3A;True</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>
</code></pre>
</li>
</ol>
<h4 id="43-----robots&#x534F;&#x8BAE;">4.3     robots&#x534F;&#x8BAE;</h4>
<blockquote>
<p>&#x5728;&#x767E;&#x5EA6;&#x641C;&#x7D22;&#x4E2D;&#xFF0C;&#x4E0D;&#x80FD;&#x641C;&#x7D22;&#x5230;&#x6DD8;&#x5B9D;&#x7F51;&#x4E2D;&#x67D0;&#x4E00;&#x4E2A;&#x5177;&#x4F53;&#x7684;&#x5546;&#x54C1;&#x7684;&#x8BE6;&#x60C5;&#x9875;&#x9762;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;robots&#x534F;&#x8BAE;&#x5728;&#x8D77;&#x4F5C;&#x7528;</p>
</blockquote>
<ul>
<li><p>Robots&#x534F;&#x8BAE;&#xFF1A;&#x7F51;&#x7AD9;&#x901A;&#x8FC7;Robots&#x534F;&#x8BAE;&#x544A;&#x8BC9;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x54EA;&#x4E9B;&#x9875;&#x9762;&#x53EF;&#x4EE5;&#x6293;&#x53D6;&#xFF0C;&#x54EA;&#x4E9B;&#x9875;&#x9762;&#x4E0D;&#x80FD;&#x6293;&#x53D6;&#xFF0C;&#x4F46;&#x5B83;&#x4EC5;&#x4EC5;&#x662F;&#x4E92;&#x8054;&#x7F51;&#x4E2D;&#x7684;&#x4E00;&#x822C;&#x7EA6;&#x5B9A;</p>
</li>
<li><p>&#x4F8B;&#x5982;&#xFF1A;<a href="https://www.taobao.com/robots.txt" target="_blank">&#x6DD8;&#x5B9D;&#x7684;robots&#x534F;&#x8BAE;</a></p>
</li>
</ul>
<h3 id="5-scrapyrequest&#x7684;&#x66F4;&#x591A;&#x53C2;&#x6570;">5. scrapy.Request&#x7684;&#x66F4;&#x591A;&#x53C2;&#x6570;</h3>
<pre><code class="lang-python">scrapy.Request(url[,callback,method=<span class="hljs-string">&quot;GET&quot;</span>,headers,body,cookies,\
meta,dont_filter=<span class="hljs-keyword">False</span>])
</code></pre>
<h5 id="&#x53C2;&#x6570;&#x89E3;&#x91CA;">&#x53C2;&#x6570;&#x89E3;&#x91CA;</h5>
<ol>
<li>&#x4E2D;&#x62EC;&#x53F7;&#x91CC;&#x7684;&#x53C2;&#x6570;&#x4E3A;&#x53EF;&#x9009;&#x53C2;&#x6570;</li>
<li>callback&#xFF1A;&#x8868;&#x793A;&#x5F53;&#x524D;&#x7684;url&#x7684;&#x54CD;&#x5E94;&#x4EA4;&#x7ED9;&#x54EA;&#x4E2A;&#x51FD;&#x6570;&#x53BB;&#x5904;&#x7406;</li>
<li>meta&#xFF1A;&#x5B9E;&#x73B0;&#x6570;&#x636E;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#xFF0C;meta&#x9ED8;&#x8BA4;&#x5E26;&#x6709;&#x90E8;&#x5206;&#x6570;&#x636E;&#xFF0C;&#x6BD4;&#x5982;&#x4E0B;&#x8F7D;&#x5EF6;&#x8FDF;&#xFF0C;&#x8BF7;&#x6C42;&#x6DF1;&#x5EA6;&#x7B49;</li>
<li>dont_filter:&#x9ED8;&#x8BA4;&#x4E3A;False&#xFF0C;&#x4F1A;&#x8FC7;&#x6EE4;&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x5373;&#x8BF7;&#x6C42;&#x8FC7;&#x7684;url&#x5730;&#x5740;&#x4E0D;&#x4F1A;&#x7EE7;&#x7EED;&#x88AB;&#x8BF7;&#x6C42;&#xFF0C;&#x5BF9;&#x9700;&#x8981;&#x91CD;&#x590D;&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;&#x53EF;&#x4EE5;&#x628A;&#x5B83;&#x8BBE;&#x7F6E;&#x4E3A;Ture&#xFF0C;&#x6BD4;&#x5982;&#x8D34;&#x5427;&#x7684;&#x7FFB;&#x9875;&#x8BF7;&#x6C42;&#xFF0C;&#x9875;&#x9762;&#x7684;&#x6570;&#x636E;&#x603B;&#x662F;&#x5728;&#x53D8;&#x5316;;start_urls&#x4E2D;&#x7684;&#x5730;&#x5740;&#x4F1A;&#x88AB;&#x53CD;&#x590D;&#x8BF7;&#x6C42;&#xFF0C;&#x5426;&#x5219;&#x7A0B;&#x5E8F;&#x4E0D;&#x4F1A;&#x542F;&#x52A8;</li>
<li>method&#xFF1A;&#x6307;&#x5B9A;POST&#x6216;GET&#x8BF7;&#x6C42;</li>
<li>headers&#xFF1A;&#x63A5;&#x6536;&#x4E00;&#x4E2A;&#x5B57;&#x5178;&#xFF0C;&#x5176;&#x4E2D;&#x4E0D;&#x5305;&#x62EC;cookies</li>
<li>cookies&#xFF1A;&#x63A5;&#x6536;&#x4E00;&#x4E2A;&#x5B57;&#x5178;&#xFF0C;&#x4E13;&#x95E8;&#x653E;&#x7F6E;cookies</li>
<li>body&#xFF1A;&#x63A5;&#x6536;json&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x4E3A;POST&#x7684;&#x6570;&#x636E;&#xFF0C;&#x53D1;&#x9001;payload_post&#x8BF7;&#x6C42;&#x65F6;&#x4F7F;&#x7528;&#xFF08;&#x5728;&#x4E0B;&#x4E00;&#x7AE0;&#x8282;&#x4E2D;&#x4F1A;&#x4ECB;&#x7ECD;post&#x8BF7;&#x6C42;&#xFF09;</li>
</ol>
<h3 id="6-meta&#x53C2;&#x6570;&#x7684;&#x4F7F;&#x7528;">6. meta&#x53C2;&#x6570;&#x7684;&#x4F7F;&#x7528;</h3>
<blockquote>
<ol>
<li>&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x6211;&#x4EEC;&#x53EA;&#x5728;&#x5217;&#x8868;&#x9875;&#x63D0;&#x53D6;title&#x5B57;&#x6BB5;&#xFF0C;&#x73B0;&#x5728;&#x589E;&#x52A0;&#x9700;&#x6C42;&#xFF1A;&#x989D;&#x5916;&#x63D0;&#x53D6;&#x8BE6;&#x60C5;&#x9875;&#x4E2D;&#x7684;&#x5DE5;&#x4F5C;&#x804C;&#x8D23;&#x3002;</li>
<li>&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x63D0;&#x53D6;&#x8BE6;&#x60C5;&#x9875;&#x7684;url&#x6784;&#x9020;Request&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x5728;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x4E4B;&#x540E;&#x63D0;&#x53D6;&#x5DE5;&#x4F5C;&#x804C;&#x8D23;</li>
<li>&#x518D;&#x628A;&#x5728;&#x4E0D;&#x540C;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x63D0;&#x53D6;&#x7684;&#x6570;&#x636E;&#x7EC4;&#x88C5;&#x6210;&#x4E00;&#x6761;&#x6570;&#x636E;&#xFF0C;&#x8FD9;&#x5C31;&#x9700;&#x8981;&#x6211;&#x4EEC;&#x638C;&#x63E1;meta&#x53C2;&#x6570;&#x7684;&#x4F7F;&#x7528;</li>
</ol>
</blockquote>
<h4 id="61-meta&#x7684;&#x4F5C;&#x7528;&#xFF1A;meta&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;&#x6570;&#x636E;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x7684;&#x4F20;&#x9012;">6.1 meta&#x7684;&#x4F5C;&#x7528;&#xFF1A;meta&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;&#x6570;&#x636E;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x7684;&#x4F20;&#x9012;</h4>
<h4 id="62-meta&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;">6.2 meta&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;</h4>
<ul>
<li>&#x5411;callback&#x6307;&#x5B9A;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#x6570;&#x636E;&#xFF1A;<ul>
<li><code>yield scrapy.Request(url, callback=func, meta={&apos;&#x81EA;&#x5B9A;&#x4E49;key&apos;:&apos;&#x8981;&#x4F20;&#x9012;&#x7684;&#x6570;&#x636E;&apos;})</code></li>
</ul>
</li>
<li>&#x5728;callback&#x6307;&#x5B9A;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x53D6;&#x51FA;&#x4F20;&#x9012;&#x7684;&#x6570;&#x636E;&#xFF1A;<ul>
<li><code>&#x4F20;&#x9012;&#x7684;&#x6570;&#x636E; = response.meta[&apos;&#x81EA;&#x5B9A;&#x4E49;&#x7684;key&apos;]</code></li>
</ul>
</li>
</ul>
<h4 id="63-&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#xFF1A;">6.3 &#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#xFF1A;</h4>
<ul>
<li><p>&#x722C;&#x866B;&#x6587;&#x4EF6;&#x7684;parse&#x51FD;&#x6570;&#x4E0D;&#x518D;&#x8FD4;&#x56DE;&#x6570;&#x636E;&#xFF0C;&#x800C;&#x662F;&#x6784;&#x9020;&#x8BE6;&#x60C5;&#x9875;&#x7684;&#x8BF7;&#x6C42;&#x3001;&#x4F7F;&#x7528;meta&#x53C2;&#x6570;&#x4F20;&#x9012;&#x63D0;&#x53D6;&#x7684;&#x6570;&#x636E;&#x5E76;&#x8FD4;&#x56DE;&#xFF1A;</p>
<pre><code class="lang-python">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        ...
        <span class="hljs-comment"># yield item</span>
        <span class="hljs-keyword">yield</span> scrapy.Request(detail_url, callback=self.parse_detail, meta={<span class="hljs-string">&quot;item&quot;</span>:item})
</code></pre>
</li>
<li><p>&#x518D;&#x589E;&#x52A0;&#x4E13;&#x95E8;&#x89E3;&#x6790;&#x8BE6;&#x60C5;&#x9875;&#x7684;parse_detail&#x51FD;&#x6570;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_detail</span><span class="hljs-params">(self,response)</span>:</span>
    <span class="hljs-comment">#&#x83B7;&#x53D6;&#x4E4B;&#x524D;&#x4F20;&#x5165;&#x7684;item</span>
    item = resposne.meta[<span class="hljs-string">&quot;item&quot;</span>]
    item[<span class="hljs-string">&apos;content&apos;</span>] = response.xpath(<span class="hljs-string">&apos;//ul[@class=&quot;squareli&quot;]//text()&apos;</span>).extract() <span class="hljs-comment"># &#x63D0;&#x53D6;&#x5DE5;&#x4F5C;&#x804C;&#x8D23;&#xFF0C;&#x5E76;&#x7EC4;&#x88C5;&#x6570;&#x636E;</span>
    <span class="hljs-keyword">yield</span> item <span class="hljs-comment"># &#x6700;&#x7EC8;&#x8FD4;&#x56DE;&#x4E00;&#x6761;&#x6570;&#x636E;</span>
</code></pre>
</li>
</ul>
<h4 id="64-&#x7279;&#x522B;&#x6CE8;&#x610F;">6.4 &#x7279;&#x522B;&#x6CE8;&#x610F;</h4>
<ol>
<li><p>meta&#x53C2;&#x6570;&#x662F;&#x4E00;&#x4E2A;&#x5B57;&#x5178;</p>
</li>
<li><p>meta&#x5B57;&#x5178;&#x4E2D;&#x6709;&#x4E00;&#x4E2A;&#x56FA;&#x5B9A;&#x7684;&#x952E;<code>proxy</code>&#xFF0C;&#x8868;&#x793A;&#x4EE3;&#x7406;ip&#xFF0C;&#x5173;&#x4E8E;&#x4EE3;&#x7406;ip&#x7684;&#x4F7F;&#x7528;&#x6211;&#x4EEC;&#x5C06;&#x5728;scrapy&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5B66;&#x4E60;&#x4E2D;&#x8FDB;&#x884C;&#x4ECB;&#x7ECD;&#xFF0C;&#x8FD9;&#x91CC;&#x4E0D;&#x505A;&#x5C55;&#x5F00;</p>
</li>
</ol>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528;-&#x5229;&#x7528;meta&#x53C2;&#x6570;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#x6570;&#x636E;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x5E94;&#x7528; &#x5229;&#x7528;meta&#x53C2;&#x6570;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#x6570;&#x636E;</h5>
<hr>
<h3 id="7-baseitem&#x7684;&#x4F7F;&#x7528;">7. BaseItem&#x7684;&#x4F7F;&#x7528;</h3>
<blockquote>
<p>&#x6253;&#x5F00;items.py&#x6587;&#x4EF6;&#xFF0C;&#x5B9A;&#x4E49;BaseItem&#x5B57;&#x6BB5;&#x7C7B;</p>
</blockquote>
<h4 id="71-baseitem&#x80FD;&#x591F;&#x505A;&#x4EC0;&#x4E48;">7.1 BaseItem&#x80FD;&#x591F;&#x505A;&#x4EC0;&#x4E48;</h4>
<ul>
<li><p>&#x5B9A;&#x4E49;item&#x5373;&#x63D0;&#x524D;&#x89C4;&#x5212;&#x597D;&#x54EA;&#x4E9B;&#x5B57;&#x6BB5;&#x9700;&#x8981;&#x6293;&#x53D6;&#xFF0C;&#x9632;&#x6B62;&#x624B;&#x8BEF;&#xFF1B;&#x914D;&#x5408;&#x6CE8;&#x91CA;&#x4E00;&#x8D77;&#x53EF;&#x4EE5;&#x6E05;&#x6670;&#x7684;&#x77E5;&#x9053;&#x8981;&#x6293;&#x53D6;&#x54EA;&#x4E9B;&#x5B57;&#x6BB5;&#xFF1B;&#x6CA1;&#x6709;&#x5B9A;&#x4E49;&#x7684;&#x5B57;&#x6BB5;&#x4E0D;&#x80FD;&#x6293;&#x53D6;&#xFF1B;&#x5728;&#x5B57;&#x6BB5;&#x4E0D;&#x591A;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x5F88;&#x5C11;&#x4F7F;&#x7528;&#xFF1B;&#x53EF;&#x4EE5;&#x5728;&#x722C;&#x866B;&#x4E2D;&#x81EA;&#x5B9A;&#x4E49;&#x6570;&#x636E;&#x5B57;&#x5178;&#x6765;&#x4EE3;&#x66FF;</p>
</li>
<li><p>&#x5728;python&#x5927;&#x591A;&#x6570;&#x6846;&#x67B6;&#x4E2D;&#xFF0C;&#x5927;&#x591A;&#x6570;&#x6846;&#x67B6;&#x90FD;&#x4F1A;&#x81EA;&#x5B9A;&#x4E49;&#x81EA;&#x5DF1;&#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;(&#x5728;python&#x81EA;&#x5E26;&#x7684;&#x6570;&#x636E;&#x7ED3;&#x6784;&#x57FA;&#x7840;&#x4E0A;&#x8FDB;&#x884C;&#x5C01;&#x88C5;)&#xFF0C;&#x76EE;&#x7684;&#x662F;&#x589E;&#x52A0;&#x529F;&#x80FD;&#xFF0C;&#x589E;&#x52A0;&#x81EA;&#x5B9A;&#x4E49;&#x5F02;&#x5E38;</p>
<ul>
<li>&#x5982;<code>response.xpath()</code>&#x7684;&#x8FD4;&#x56DE;&#x5BF9;&#x8C61;&#x5177;&#x6709;<code>extract()</code>&#x7B49;&#x65B9;&#x6CD5;</li>
</ul>
</li>
</ul>
<h4 id="72-&#x5B9A;&#x4E49;baseitem">7.2 &#x5B9A;&#x4E49;BaseItem</h4>
<p>&#x5728;items.py&#x6587;&#x4EF6;&#x4E2D;&#x5B9A;&#x4E49;&#x8981;&#x63D0;&#x53D6;&#x7684;&#x5B57;&#x6BB5;&#xFF1A;</p>
<pre><code>class TencentItem(scrapy.Item): 
    name = scrapy.Field() # &#x62DB;&#x8058;&#x6807;&#x9898;
    content = scrapy.Field() # &#x5DE5;&#x4F5C;&#x804C;&#x8D23;
</code></pre><h4 id="73-&#x4F7F;&#x7528;baseitem">7.3 &#x4F7F;&#x7528;BaseItem</h4>
<p>BaseItem&#x9876;&#x4EE5;&#x540E;&#x9700;&#x8981;&#x5728;&#x722C;&#x866B;&#x4E2D;&#x5BFC;&#x5165;&#x5E76;&#x4E14;&#x5B9E;&#x4F8B;&#x5316;&#xFF0C;&#x4E4B;&#x540E;&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#x548C;&#x4F7F;&#x7528;&#x5B57;&#x5178;&#x76F8;&#x540C;</p>
<p>&#x4FEE;&#x6539;&#x722C;&#x866B;&#x6587;&#x4EF6;tencent.py&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> Tencent.items <span class="hljs-keyword">import</span> TencentItem <span class="hljs-comment"># &#x5BFC;&#x5165;Item&#xFF0C;&#x6CE8;&#x610F;&#x8DEF;&#x5F84;</span>
...
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_detail</span><span class="hljs-params">(self, response)</span>:</span>
        meta_dict = response.meta <span class="hljs-comment"># &#x83B7;&#x53D6;&#x4F20;&#x5165;&#x7684;meta</span>

        item = TencentItem() <span class="hljs-comment"># &#x5B9E;&#x4F8B;&#x5316;&#x540E;&#x53EF;&#x76F4;&#x63A5;&#x4F7F;&#x7528;</span>
        item[<span class="hljs-string">&apos;title&apos;</span>] = meta_dict[<span class="hljs-string">&apos;title&apos;</span>]
        <span class="hljs-comment"># &#x52A0;&#x5165;&#x5C97;&#x4F4D;&#x804C;&#x8D23;&#x6570;&#x636E;</span>
        item[<span class="hljs-string">&apos;job_content&apos;</span>] = response.xpath(<span class="hljs-string">&apos;//ul[@class=&quot;squareli&quot;]/li/text()&apos;</span>).extract() 

        <span class="hljs-keyword">yield</span> item
</code></pre>
<h4 id="74-&#x6CE8;&#x610F;&#xFF1A;">7.4 &#x6CE8;&#x610F;&#xFF1A;</h4>
<ol>
<li><code>from Tencent.items import TencentItem</code>&#x8FD9;&#x4E00;&#x884C;&#x4EE3;&#x7801;&#x4E2D; &#x6CE8;&#x610F;&#x5BFC;&#x5165;&#x8DEF;&#x5F84;&#xFF0C;&#x8BF7;&#x5FFD;&#x7565;pycharm&#x6807;&#x8BB0;&#x7684;&#x9519;&#x8BEF;</li>
<li>python&#x4E2D;&#x7684;&#x5BFC;&#x5165;&#x8DEF;&#x5F84;&#x8981;&#x8BC0;&#xFF1A;&#x4ECE;&#x54EA;&#x91CC;&#x5F00;&#x59CB;&#x8FD0;&#x884C;&#xFF0C;&#x5C31;&#x4ECE;&#x54EA;&#x91CC;&#x5F00;&#x59CB;&#x5BFC;&#x5165;</li>
</ol>
<hr>
<h3 id="&#x53C2;&#x8003;&#x4EE3;&#x7801;">&#x53C2;&#x8003;&#x4EE3;&#x7801;</h3>
<ul>
<li>Tencent/spiders/tencent.py</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> Tencent.items <span class="hljs-keyword">import</span> TencentItem <span class="hljs-comment"># &#x5BFC;&#x5165;Item&#xFF0C;&#x6CE8;&#x610F;&#x8DEF;&#x5F84;</span>


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TencentSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;tencent&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;hr.tencent.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;http://hr.tencent.com/position.php&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>

        tr_list = response.xpath(<span class="hljs-string">&apos;//*[@class=&quot;tablelist&quot;]//tr&apos;</span>)[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]
        <span class="hljs-keyword">for</span> tr <span class="hljs-keyword">in</span> tr_list:
            meta_dict = {}
            meta_dict[<span class="hljs-string">&apos;name&apos;</span>] = tr.xpath(<span class="hljs-string">&apos;.//a[1]/text()&apos;</span>).extract_first()
            meta_dict[<span class="hljs-string">&apos;address&apos;</span>] = tr.xpath(<span class="hljs-string">&apos;./td[4]/text()&apos;</span>).extract_first()
            meta_dict[<span class="hljs-string">&apos;time&apos;</span>] = tr.xpath(<span class="hljs-string">&apos;./td[5]/text()&apos;</span>).extract_first()
            meta_dict[<span class="hljs-string">&apos;href&apos;</span>] = tr.xpath(<span class="hljs-string">&apos;.//a[1]/@href&apos;</span>).extract_first()
            detail_url = <span class="hljs-string">&apos;https://hr.tencent.com/&apos;</span> + meta_dict[<span class="hljs-string">&apos;href&apos;</span>]
            <span class="hljs-keyword">yield</span> scrapy.Request(detail_url, callback=self.parse_detail, meta=meta_dict)

        <span class="hljs-comment"># &#x63D0;&#x53D6;&#x4E0B;&#x4E00;&#x9875;&#x7684;href&#x5E76;&#x62FC;&#x63A5;url</span>
        next_url = <span class="hljs-string">&apos;https://hr.tencent.com/&apos;</span> + response.xpath(<span class="hljs-string">&apos;//a[text()=&quot;&#x4E0B;&#x4E00;&#x9875;&quot;]/@href&apos;</span>).extract_first()
        <span class="hljs-comment"># &#x5224;&#x65AD;&#x662F;&#x5426;&#x662F;&#x6700;&#x540E;&#x4E00;&#x9875;</span>
        <span class="hljs-keyword">if</span> response.xpath(<span class="hljs-string">&apos;//a[text()=&quot;&#x4E0B;&#x4E00;&#x9875;&quot;]/@href&apos;</span>).extract_first() != <span class="hljs-string">&apos;javascript:;&apos;</span>:
            <span class="hljs-comment"># &#x6784;&#x9020;scrapy.Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;yield&#x7ED9;&#x5F15;&#x64CE;</span>
            <span class="hljs-comment"># &#x5229;&#x7528;callback&#x53C2;&#x6570;&#x6307;&#x5B9A;&#x8BE5;Request&#x5BF9;&#x8C61;&#x4E4B;&#x540E;&#x83B7;&#x53D6;&#x7684;&#x54CD;&#x5E94;&#x7528;&#x54EA;&#x4E2A;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x89E3;&#x6790;</span>
            <span class="hljs-comment"># &#x5229;&#x7528;meta&#x53C2;&#x6570;&#x5C06;&#x672C;&#x51FD;&#x6570;&#x4E2D;&#x63D0;&#x53D6;&#x7684;&#x6570;&#x636E;&#x4F20;&#x9012;&#x7ED9;callback&#x6307;&#x5B9A;&#x7684;&#x51FD;&#x6570;</span>
            <span class="hljs-comment"># &#x6CE8;&#x610F;&#x8FD9;&#x91CC;&#x662F;yield</span>
            <span class="hljs-keyword">yield</span> scrapy.Request(next_url, callback=self.parse)


    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_detail</span><span class="hljs-params">(self,response)</span>:</span>
        meta_dict = response.meta  <span class="hljs-comment"># &#x83B7;&#x53D6;&#x4F20;&#x5165;&#x7684;meta</span>

        item = TencentItem()  <span class="hljs-comment"># &#x5B9E;&#x4F8B;&#x5316;&#x540E;&#x53EF;&#x76F4;&#x63A5;&#x4F7F;&#x7528;</span>
        item[<span class="hljs-string">&apos;name&apos;</span>] = meta_dict[<span class="hljs-string">&apos;name&apos;</span>]
        item[<span class="hljs-string">&apos;address&apos;</span>] = meta_dict[<span class="hljs-string">&apos;address&apos;</span>]
        item[<span class="hljs-string">&apos;time&apos;</span>] = meta_dict[<span class="hljs-string">&apos;time&apos;</span>]

        <span class="hljs-comment"># &#x52A0;&#x5165;&#x5C97;&#x4F4D;&#x804C;&#x8D23;&#x6570;&#x636E;</span>
        item[<span class="hljs-string">&apos;job_content&apos;</span>] = response.xpath(<span class="hljs-string">&apos;//ul[@class=&quot;squareli&quot;]/li/text()&apos;</span>).extract()

        print(item)
</code></pre>
<ul>
<li>Tencent/items.py</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TencentItem</span><span class="hljs-params">(scrapy.Item)</span>:</span>
    name = scrapy.Field() <span class="hljs-comment"># &#x62DB;&#x8058;&#x6807;&#x9898;</span>
    address = scrapy.Field() <span class="hljs-comment"># &#x5DE5;&#x4F5C;&#x5730;&#x5740;</span>
    time = scrapy.Field() <span class="hljs-comment"># &#x53D1;&#x5E03;&#x65F6;&#x95F4;</span>
    job_content = scrapy.Field() <span class="hljs-comment"># &#x5DE5;&#x4F5C;&#x804C;&#x8D23;</span>
</code></pre>
<ul>
<li>Tencent/settings.py</li>
</ul>
<pre><code class="lang-python">USER_AGENT = <span class="hljs-string">&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&apos;</span>

ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>
</code></pre>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; ITCast all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x300C;Revision Time:
2019-02-28 01:57:23&#x300D;
</span></footer>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html" class="navigation navigation-prev " aria-label="Previous page: scrapy的入门使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html" class="navigation navigation-next " aria-label="Next page: scrapy模拟登陆"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"disqus":{"shortName":"gitbookuse"},"github":{"url":"https://github.com/dododream"},"search-pro":{"cutWordLib":"nodejieba","defineWord":["gitbook-use"]},"sharing":{"weibo":true,"facebook":true,"twitter":true,"google":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"tbfed-pagefooter":{"copyright":"Copyright © ITCast","modify_label":"「Revision Time:","modify_format":"YYYY-MM-DD HH:mm:ss」"},"baidu":{"token":"ff100361cdce95dd4c8fb96b4009f7bc"},"sitemap":{"hostname":"http://www.treenewbee.top"},"donate":{"wechat":"http://weixin.png","alipay":"http://alipay.png","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"edit-link":{"base":"https://github.com/dododream/edit","label":"Edit This Page"},"splitter":{},"toggle-chapters":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
    </body>
    <!-- End of book Python爬虫课程讲义 -->
</html>
