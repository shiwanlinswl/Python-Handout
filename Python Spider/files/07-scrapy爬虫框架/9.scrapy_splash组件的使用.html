<!DOCTYPE HTML>
<html lang="en" >
    <!-- Start book Python爬虫课程讲义 -->
    <head>
        <!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy_splash组件的使用 | Python爬虫课程讲义</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        <meta name="author" content="BigCat">
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-tbfed-pagefooter/footer.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html" />
    
    
    <link rel="prev" href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html" />
    

        <!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
        
    <div class="book"
        data-level="7.9"
        data-chapter-title="scrapy_splash组件的使用"
        data-filepath="files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.md"
        data-basepath="../.."
        data-revision="Thu Feb 28 2019 03:09:16 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        传智播客Python学科爬虫课件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="files/01-爬虫基础/index.html">
            
                
                    <a href="../../files/01-爬虫基础/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        网络爬虫知识基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="files/01-爬虫基础/1.爬虫概述.html">
            
                
                    <a href="../../files/01-爬虫基础/1.爬虫概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫概述与分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
            
                
                    <a href="../../files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        (了解) 通用爬虫和聚焦爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="files/01-爬虫基础/3.爬虫基础知识.html">
            
                
                    <a href="../../files/01-爬虫基础/3.爬虫基础知识.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        爬虫基础知识
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="files/01-爬虫基础/4.http协议复习.html">
            
                
                    <a href="../../files/01-爬虫基础/4.http协议复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        (复习) http协议复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="files/02-requests模块/index.html">
            
                
                    <a href="../../files/02-requests模块/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        HTTP请求处理工具：requests
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="files/02-requests模块/requests模块1.html">
            
                
                    <a href="../../files/02-requests模块/requests模块1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        requests模块处理的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="files/02-requests模块/requests模块2.html">
            
                
                    <a href="../../files/02-requests模块/requests模块2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        requests模块处理Cookie和Proxy高级功能
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="files/02-requests模块/requests模块3.html">
            
                
                    <a href="../../files/02-requests模块/requests模块3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        requests模块处理post请求与session会话保持
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="files/03-数据提取/index.html">
            
                
                    <a href="../../files/03-数据提取/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        HTTP数据提取工具：jsonpath 和 lxml/xpath
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="files/03-数据提取/1.数据提取概述.html">
            
                
                    <a href="../../files/03-数据提取/1.数据提取概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        数据提取概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="files/03-数据提取/2.数据提取-jsonpath模块.html">
            
                
                    <a href="../../files/03-数据提取/2.数据提取-jsonpath模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        数据提取-jsonpath模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="files/03-数据提取/3.数据提取-lxml模块.html">
            
                
                    <a href="../../files/03-数据提取/3.数据提取-lxml模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        数据提取-lxml模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="files/04-selenium的使用/index.html">
            
                
                    <a href="../../files/04-selenium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        web自动化测试工具：selenium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="files/04-selenium的使用/1.selenium的介绍.html">
            
                
                    <a href="../../files/04-selenium的使用/1.selenium的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        selenium的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
            
                
                    <a href="../../files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium定位获取标签对象并提取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="files/04-selenium的使用/3.selenium的其它使用方法.html">
            
                
                    <a href="../../files/04-selenium的使用/3.selenium的其它使用方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        selenium的其它使用方法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="files/05-抓包、反爬与反爬解决方案/index.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        抓包、反爬与反爬解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        常见的反爬手段、原理以及应对思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        打码平台处理验证码
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        chrome浏览器的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        js2py模块的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.5" data-path="files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        cookie池和代理池
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="files/06-mongodb数据库/index.html">
            
                
                    <a href="../../files/06-mongodb数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        MongoDB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="files/06-mongodb数据库/1.mongodb介绍和安装.html">
            
                
                    <a href="../../files/06-mongodb数据库/1.mongodb介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        mongodb介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="files/06-mongodb数据库/2.mongodb的简单使用.html">
            
                
                    <a href="../../files/06-mongodb数据库/2.mongodb的简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        mongodb的简单使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="files/06-mongodb数据库/3.mongodb的增删改查.html">
            
                
                    <a href="../../files/06-mongodb数据库/3.mongodb的增删改查.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        mongodb的增删改查
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="files/06-mongodb数据库/4.mongodb的索引操作.html">
            
                
                    <a href="../../files/06-mongodb数据库/4.mongodb的索引操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.4.</b>
                        
                        mongodb的索引操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="files/06-mongodb数据库/5.mongodb的权限管理.html">
            
                
                    <a href="../../files/06-mongodb数据库/5.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.5.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.6" data-path="files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
            
                
                    <a href="../../files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.6.</b>
                        
                        mongodb和python交互（pymongo模块的使用）
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="files/07-scrapy爬虫框架/index.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Scrapy爬虫框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.3.</b>
                        
                        scrapy构造并发送请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.4.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.6.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.7" data-path="files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.7.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.8" data-path="files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.8.</b>
                        
                        scrapy_redis原理分析并实现断点续爬以及分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7.9" data-path="files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.9.</b>
                        
                        scrapy_splash组件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.10" data-path="files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.10.</b>
                        
                        scrapy的日志信息与配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.11" data-path="files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.11.</b>
                        
                        scrapyd部署scrapy项目
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="files/08-appium的使用/index.html">
            
                
                    <a href="../../files/08-appium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        移动端APP自动化测试工具：appium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="files/08-appium的使用/1.appium环境安装.html">
            
                
                    <a href="../../files/08-appium的使用/1.appium环境安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        appium环境安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
            
                
                    <a href="../../files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        利用appium自动控制移动设备并提取数据
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="files/09-项目-12306购票（requests）/index.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        项目：12306购票（requests）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        12306购票抓包分析以及任务分解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        处理验证码并完成登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.3" data-path="files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.3.</b>
                        
                        解析车站信息以及车辆信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.4" data-path="files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.4.</b>
                        
                        预定订单初始化、解析用户信息以及坐席信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.5" data-path="files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.5.</b>
                        
                        构造时间参数以及下单购票
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.6" data-path="files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.6.</b>
                        
                        测试运行以及完整代码
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="files/10-项目-国家企业公示网（selenium）/index.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        项目：国家企业公示网（selenium）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="10.1" data-path="files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.1.</b>
                        
                        项目分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.2.</b>
                        
                        webapi实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.3.</b>
                        
                        node_server节点任务调度
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.4.</b>
                        
                        crawler爬虫抓取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.5.</b>
                        
                        运行效果
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="11" data-path="files/duanzi/duanzi.html">
            
                
                    <a href="../../files/duanzi/duanzi.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        课余段子
                    </a>
            
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >Python爬虫课程讲义</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="scrapysplash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;">scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;">&#x5B66;&#x4E60;&#x76EE;&#x6807;</h5>
<ul>
<li>&#x4E86;&#x89E3; scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F5C;&#x7528;</li>
<li>&#x4E86;&#x89E3; scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;</li>
</ul>
<hr>
<h3 id="1-&#x4EC0;&#x4E48;&#x662F;scrapysplash&#xFF1F;">1. &#x4EC0;&#x4E48;&#x662F;scrapy_splash&#xFF1F;</h3>
<p>scrapy_splash&#x662F;scrapy&#x7684;&#x4E00;&#x4E2A;&#x7EC4;&#x4EF6;</p>
<blockquote>
<ul>
<li>scrapy-splash&#x52A0;&#x8F7D;js&#x6570;&#x636E;&#x662F;&#x57FA;&#x4E8E;Splash&#x6765;&#x5B9E;&#x73B0;&#x7684;&#x3002;</li>
<li>Splash&#x662F;&#x4E00;&#x4E2A;Javascript&#x6E32;&#x67D3;&#x670D;&#x52A1;&#x3002;&#x5B83;&#x662F;&#x4E00;&#x4E2A;&#x5B9E;&#x73B0;&#x4E86;HTTP API&#x7684;&#x8F7B;&#x91CF;&#x7EA7;&#x6D4F;&#x89C8;&#x5668;&#xFF0C;Splash&#x662F;&#x7528;Python&#x548C;Lua&#x8BED;&#x8A00;&#x5B9E;&#x73B0;&#x7684;&#xFF0C;&#x57FA;&#x4E8E;Twisted&#x548C;QT&#x7B49;&#x6A21;&#x5757;&#x6784;&#x5EFA;&#x3002;</li>
<li>&#x4F7F;&#x7528;scrapy-splash&#x6700;&#x7EC8;&#x62FF;&#x5230;&#x7684;response&#x76F8;&#x5F53;&#x4E8E;&#x662F;&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x5168;&#x90E8;&#x6E32;&#x67D3;&#x5B8C;&#x6210;&#x4EE5;&#x540E;&#x7684;&#x7F51;&#x9875;&#x6E90;&#x4EE3;&#x7801;&#x3002;</li>
</ul>
<p>splash&#x5B98;&#x65B9;&#x6587;&#x6863; <a href="https://splash.readthedocs.io/en/stable/" target="_blank">https://splash.readthedocs.io/en/stable/</a></p>
</blockquote>
<h3 id="2-scrapysplash&#x7684;&#x4F5C;&#x7528;">2. scrapy_splash&#x7684;&#x4F5C;&#x7528;</h3>
<p>scrapy-splash&#x80FD;&#x591F;&#x6A21;&#x62DF;&#x6D4F;&#x89C8;&#x5668;&#x52A0;&#x8F7D;js&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;js&#x8FD0;&#x884C;&#x540E;&#x7684;&#x6570;&#x636E;</p>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;-scrapysplash&#x7EC4;&#x4EF6;&#x7684;&#x4F5C;&#x7528;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3; scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F5C;&#x7528;</h5>
<hr>
<h3 id="3-scrapysplash&#x7684;&#x73AF;&#x5883;&#x5B89;&#x88C5;">3. scrapy_splash&#x7684;&#x73AF;&#x5883;&#x5B89;&#x88C5;</h3>
<h4 id="31-&#x4F7F;&#x7528;splash&#x7684;docker&#x955C;&#x50CF;">3.1 &#x4F7F;&#x7528;splash&#x7684;docker&#x955C;&#x50CF;</h4>
<blockquote>
<p>splash&#x7684;dockerfile <a href="https://github.com/scrapinghub/splash/blob/master/Dockerfile" target="_blank">https://github.com/scrapinghub/splash/blob/master/Dockerfile</a></p>
</blockquote>
<p>&#x89C2;&#x5BDF;&#x53D1;&#x73B0;splash&#x4F9D;&#x8D56;&#x73AF;&#x5883;&#x7565;&#x5FAE;&#x590D;&#x6742;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4F7F;&#x7528;splash&#x7684;docker&#x955C;&#x50CF;</p>
<p>&#x5982;&#x679C;&#x4E0D;&#x4F7F;&#x7528;docker&#x955C;&#x50CF;&#x8BF7;&#x53C2;&#x8003; <a href="https://github.com/scrapinghub/splash/blob/master/Dockerfile" target="_blank">splash&#x5B98;&#x65B9;&#x6587;&#x6863;</a> &#x5B89;&#x88C5;&#x76F8;&#x5E94;&#x7684;&#x4F9D;&#x8D56;&#x73AF;&#x5883;</p>
<h5 id="311-&#x5B89;&#x88C5;&#x5E76;&#x542F;&#x52A8;docker&#x670D;&#x52A1;">3.1.1 &#x5B89;&#x88C5;&#x5E76;&#x542F;&#x52A8;docker&#x670D;&#x52A1;</h5>
<blockquote>
<p>&#x5B89;&#x88C5;&#x53C2;&#x8003; <a href="https://blog.csdn.net/sanpic/article/details/81984683" target="_blank">https://blog.csdn.net/sanpic/article/details/81984683</a></p>
</blockquote>
<h5 id="312-&#x83B7;&#x53D6;splash&#x7684;&#x955C;&#x50CF;">3.1.2 &#x83B7;&#x53D6;splash&#x7684;&#x955C;&#x50CF;</h5>
<blockquote>
<p>&#x5728;&#x6B63;&#x786E;&#x5B89;&#x88C5;docker&#x7684;&#x57FA;&#x7840;&#x4E0A;pull&#x53D6;splash&#x7684;&#x955C;&#x50CF;</p>
</blockquote>
<p><code>sudo docker pull scrapinghub/splash</code></p>
<h5 id="313-&#x9A8C;&#x8BC1;&#x662F;&#x5426;&#x5B89;&#x88C5;&#x6210;&#x529F;">3.1.3 &#x9A8C;&#x8BC1;&#x662F;&#x5426;&#x5B89;&#x88C5;&#x6210;&#x529F;</h5>
<blockquote>
<p>&#x8FD0;&#x884C;splash&#x7684;docker&#x670D;&#x52A1;&#xFF0C;&#x5E76;&#x901A;&#x8FC7;&#x6D4F;&#x89C8;&#x5668;&#x8BBF;&#x95EE;8050&#x7AEF;&#x53E3;&#x9A8C;&#x8BC1;&#x5B89;&#x88C5;&#x662F;&#x5426;&#x6210;&#x529F;</p>
</blockquote>
<ul>
<li><p>&#x524D;&#x53F0;&#x8FD0;&#x884C; <code>sudo docker run -p 8050:8050 scrapinghub/splash</code></p>
</li>
<li><p>&#x540E;&#x53F0;&#x8FD0;&#x884C; <code>sudo docker run -d -p 8050:8050 scrapinghub/splash</code></p>
</li>
</ul>
<p>&#x8BBF;&#x95EE; <a href="http://127.0.0.1:8050" target="_blank">http://127.0.0.1:8050</a> &#x770B;&#x5230;&#x5982;&#x4E0B;&#x622A;&#x56FE;&#x5185;&#x5BB9;&#x5219;&#x8868;&#x793A;&#x6210;&#x529F;</p>
<p><img src="images/9.3.1.3.splash-server.png" width="100%"></p>
<h5 id="314-&#x89E3;&#x51B3;&#x83B7;&#x53D6;&#x955C;&#x50CF;&#x8D85;&#x65F6;&#x4FEE;&#x6539;docker&#x7684;&#x955C;&#x50CF;&#x6E90;">3.1.4 &#x89E3;&#x51B3;&#x83B7;&#x53D6;&#x955C;&#x50CF;&#x8D85;&#x65F6;:&#x4FEE;&#x6539;docker&#x7684;&#x955C;&#x50CF;&#x6E90;</h5>
<blockquote>
<p>&#x4EE5;ubuntu18.04&#x4E3A;&#x4F8B;</p>
</blockquote>
<ol>
<li>&#x521B;&#x5EFA;&#x5E76;&#x7F16;&#x8F91;docker&#x7684;&#x914D;&#x7F6E;&#x6587;&#x4EF6;</li>
</ol>
<p><code>sudo vi /etc/docker/daemon.json</code></p>
<ol>
<li>&#x5199;&#x5165;&#x56FD;&#x5185;docker-cn.com&#x7684;&#x955C;&#x50CF;&#x5730;&#x5740;&#x914D;&#x7F6E;&#x540E;&#x4FDD;&#x5B58;&#x9000;&#x51FA;</li>
</ol>
<pre><code class="lang-python">{ 
<span class="hljs-string">&quot;registry-mirrors&quot;</span>: [<span class="hljs-string">&quot;https://registry.docker-cn.com&quot;</span>] 
}
</code></pre>
<ol>
<li><p>&#x91CD;&#x542F;&#x7535;&#x8111;&#x6216;docker&#x670D;&#x52A1;&#x540E;&#x91CD;&#x65B0;&#x83B7;&#x53D6;splash&#x955C;&#x50CF;</p>
</li>
<li><p>&#x8FD9;&#x65F6;&#x5982;&#x679C;&#x8FD8;&#x6162;&#xFF0C;&#x8BF7;&#x4F7F;&#x7528;&#x624B;&#x673A;&#x70ED;&#x70B9;&#xFF08;&#x6D41;&#x91CF;orz&#xFF09;</p>
</li>
</ol>
<h5 id="315-&#x5173;&#x95ED;splash&#x670D;&#x52A1;">3.1.5 &#x5173;&#x95ED;splash&#x670D;&#x52A1;</h5>
<blockquote>
<p>&#x9700;&#x8981;&#x5148;&#x5173;&#x95ED;&#x5BB9;&#x5668;&#x540E;&#xFF0C;&#x518D;&#x5220;&#x9664;&#x5BB9;&#x5668;</p>
</blockquote>
<pre><code class="lang-python">sudo docker ps -a
sudo docker stop CONTAINER_ID
sudo docker rm CONTAINER_ID
</code></pre>
<h4 id="32-&#x5728;python&#x865A;&#x62DF;&#x73AF;&#x5883;&#x4E2D;&#x5B89;&#x88C5;scrapysplash&#x5305;">3.2 &#x5728;python&#x865A;&#x62DF;&#x73AF;&#x5883;&#x4E2D;&#x5B89;&#x88C5;scrapy-splash&#x5305;</h4>
<p><code>pip install scrapy-splash</code></p>
<h3 id="4-&#x5728;scrapy&#x4E2D;&#x4F7F;&#x7528;splash">4. &#x5728;scrapy&#x4E2D;&#x4F7F;&#x7528;splash</h3>
<blockquote>
<p>&#x4EE5;baidu&#x4E3A;&#x4F8B;</p>
</blockquote>
<h4 id="41-&#x521B;&#x5EFA;&#x9879;&#x76EE;&#x521B;&#x5EFA;&#x722C;&#x866B;">4.1 &#x521B;&#x5EFA;&#x9879;&#x76EE;&#x521B;&#x5EFA;&#x722C;&#x866B;</h4>
<pre><code class="lang-python">scrapy startproject test_splash
cd test_splash
scrapy genspider no_splash baidu.com
scrapy genspider with_splash baidu.com
</code></pre>
<h4 id="42-&#x5B8C;&#x5584;settingspy&#x914D;&#x7F6E;&#x6587;&#x4EF6;">4.2 &#x5B8C;&#x5584;settings.py&#x914D;&#x7F6E;&#x6587;&#x4EF6;</h4>
<p>&#x5728;settings.py&#x6587;&#x4EF6;&#x4E2D;&#x6DFB;&#x52A0;splash&#x7684;&#x914D;&#x7F6E;&#x4EE5;&#x53CA;&#x4FEE;&#x6539;robots&#x534F;&#x8BAE;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6E32;&#x67D3;&#x670D;&#x52A1;&#x7684;url</span>
SPLASH_URL = <span class="hljs-string">&apos;http://127.0.0.1:8050&apos;</span>
<span class="hljs-comment"># &#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;</span>
DOWNLOADER_MIDDLEWARES = {
    <span class="hljs-string">&apos;scrapy_splash.SplashCookiesMiddleware&apos;</span>: <span class="hljs-number">723</span>,
    <span class="hljs-string">&apos;scrapy_splash.SplashMiddleware&apos;</span>: <span class="hljs-number">725</span>,
    <span class="hljs-string">&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;</span>: <span class="hljs-number">810</span>,
}
<span class="hljs-comment"># &#x53BB;&#x91CD;&#x8FC7;&#x6EE4;&#x5668;</span>
DUPEFILTER_CLASS = <span class="hljs-string">&apos;scrapy_splash.SplashAwareDupeFilter&apos;</span>
<span class="hljs-comment"># &#x4F7F;&#x7528;Splash&#x7684;Http&#x7F13;&#x5B58;</span>
HTTPCACHE_STORAGE = <span class="hljs-string">&apos;scrapy_splash.SplashAwareFSCacheStorage&apos;</span>

<span class="hljs-comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>
</code></pre>
<h4 id="43-&#x4E0D;&#x4F7F;&#x7528;splash">4.3 &#x4E0D;&#x4F7F;&#x7528;splash</h4>
<p>&#x5728;spiders/no_splash.py&#x4E2D;&#x5B8C;&#x5584;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NoSplashSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;no_splash&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;baidu.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;https://www.baidu.com/s?wd=13161933309&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;no_splash.html&apos;</span>, <span class="hljs-string">&apos;w&apos;</span>) <span class="hljs-keyword">as</span> f:
            f.write(response.body.decode())
</code></pre>
<h4 id="44-&#x4F7F;&#x7528;splash">4.4 &#x4F7F;&#x7528;splash</h4>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> scrapy_splash <span class="hljs-keyword">import</span> SplashRequest <span class="hljs-comment"># &#x4F7F;&#x7528;scrapy_splash&#x5305;&#x63D0;&#x4F9B;&#x7684;request&#x5BF9;&#x8C61;</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WithSplashSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;with_splash&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;baidu.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;https://www.baidu.com/s?wd=13161933309&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">yield</span> SplashRequest(self.start_urls[<span class="hljs-number">0</span>],
                            callback=self.parse_splash,
                            args={<span class="hljs-string">&apos;wait&apos;</span>: <span class="hljs-number">10</span>}, <span class="hljs-comment"># &#x6700;&#x5927;&#x8D85;&#x65F6;&#x65F6;&#x95F4;&#xFF0C;&#x5355;&#x4F4D;&#xFF1A;&#x79D2;</span>
                            endpoint=<span class="hljs-string">&apos;render.html&apos;</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;splash&#x670D;&#x52A1;&#x7684;&#x56FA;&#x5B9A;&#x53C2;&#x6570;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_splash</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;with_splash.html&apos;</span>, <span class="hljs-string">&apos;w&apos;</span>) <span class="hljs-keyword">as</span> f:
            f.write(response.body.decode())
</code></pre>
<h4 id="45-&#x5206;&#x522B;&#x8FD0;&#x884C;&#x4FE9;&#x4E2A;&#x722C;&#x866B;&#xFF0C;&#x5E76;&#x89C2;&#x5BDF;&#x73B0;&#x8C61;">4.5 &#x5206;&#x522B;&#x8FD0;&#x884C;&#x4FE9;&#x4E2A;&#x722C;&#x866B;&#xFF0C;&#x5E76;&#x89C2;&#x5BDF;&#x73B0;&#x8C61;</h4>
<h5 id="451-&#x5206;&#x522B;&#x8FD0;&#x884C;&#x4FE9;&#x4E2A;&#x722C;&#x866B;">4.5.1 &#x5206;&#x522B;&#x8FD0;&#x884C;&#x4FE9;&#x4E2A;&#x722C;&#x866B;</h5>
<pre><code>scrapy crawl no_splash
scrapy crawl with_splash
</code></pre><h5 id="452-&#x89C2;&#x5BDF;&#x83B7;&#x53D6;&#x7684;&#x4FE9;&#x4E2A;html&#x6587;&#x4EF6;">4.5.2 &#x89C2;&#x5BDF;&#x83B7;&#x53D6;&#x7684;&#x4FE9;&#x4E2A;html&#x6587;&#x4EF6;</h5>
<p>&#x4E0D;&#x4F7F;&#x7528;splash</p>
<p><img src="images/9.4.5.2.no-splash.png" width="100%"></p>
<p>&#x4F7F;&#x7528;splash</p>
<p><img src="images/9.4.5.2.with-splash.png" width="100%"></p>
<h4 id="46-&#x7ED3;&#x8BBA;">4.6 &#x7ED3;&#x8BBA;</h4>
<ol>
<li>splash&#x7C7B;&#x4F3C;selenium&#xFF0C;&#x80FD;&#x591F;&#x50CF;&#x6D4F;&#x89C8;&#x5668;&#x4E00;&#x6837;&#x8BBF;&#x95EE;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x4E2D;&#x7684;url&#x5730;&#x5740;</li>
<li>&#x80FD;&#x591F;&#x6309;&#x7167;&#x8BE5;url&#x5BF9;&#x5E94;&#x7684;&#x54CD;&#x5E94;&#x5185;&#x5BB9;&#x4F9D;&#x6B21;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</li>
<li>&#x5E76;&#x5C06;&#x591A;&#x6B21;&#x8BF7;&#x6C42;&#x5BF9;&#x5E94;&#x7684;&#x591A;&#x6B21;&#x54CD;&#x5E94;&#x5185;&#x5BB9;&#x8FDB;&#x884C;&#x6E32;&#x67D3;</li>
<li>&#x6700;&#x7EC8;&#x8FD4;&#x56DE;&#x6E32;&#x67D3;&#x540E;&#x7684;response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;</li>
</ol>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;-scrapysplash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3; scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;</h5>
<hr>
<h3 id="5-&#x4E86;&#x89E3;&#x66F4;&#x591A;">5. &#x4E86;&#x89E3;&#x66F4;&#x591A;</h3>
<ul>
<li><p>&#x5173;&#x4E8E;splash <a href="https://www.cnblogs.com/zhangxinqi/p/9279014.html" target="_blank">https://www.cnblogs.com/zhangxinqi/p/9279014.html</a></p>
</li>
<li><p>&#x5173;&#x4E8E;scrapy_splash&#xFF08;&#x622A;&#x5C4F;&#xFF0C;get_cookies&#x7B49;&#xFF09; <a href="https://www.e-learn.cn/content/qita/800748" target="_blank">https://www.e-learn.cn/content/qita/800748</a></p>
</li>
</ul>
<hr>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<ol>
<li>scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F5C;&#x7528;<ol>
<li>splash&#x7C7B;&#x4F3C;selenium&#xFF0C;&#x80FD;&#x591F;&#x50CF;&#x6D4F;&#x89C8;&#x5668;&#x4E00;&#x6837;&#x8BBF;&#x95EE;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x4E2D;&#x7684;url&#x5730;&#x5740;</li>
<li>&#x80FD;&#x591F;&#x6309;&#x7167;&#x8BE5;url&#x5BF9;&#x5E94;&#x7684;&#x54CD;&#x5E94;&#x5185;&#x5BB9;&#x4F9D;&#x6B21;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</li>
<li>&#x5E76;&#x5C06;&#x591A;&#x6B21;&#x8BF7;&#x6C42;&#x5BF9;&#x5E94;&#x7684;&#x591A;&#x6B21;&#x54CD;&#x5E94;&#x5185;&#x5BB9;&#x8FDB;&#x884C;&#x6E32;&#x67D3;</li>
<li>&#x6700;&#x7EC8;&#x8FD4;&#x56DE;&#x6E32;&#x67D3;&#x540E;&#x7684;response&#x54CD;&#x5E94;&#x5BF9;&#x8C61;</li>
</ol>
</li>
<li>scrapy_splash&#x7EC4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;<ol>
<li>&#x9700;&#x8981;splash&#x670D;&#x52A1;&#x4F5C;&#x4E3A;&#x652F;&#x6491;</li>
<li>&#x6784;&#x9020;&#x7684;request&#x5BF9;&#x8C61;&#x53D8;&#x4E3A;splash.SplashRequest</li>
<li>&#x4EE5;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5F62;&#x5F0F;&#x4F7F;&#x7528;</li>
<li>&#x9700;&#x8981;scrapy_splash&#x7279;&#x5B9A;&#x914D;&#x7F6E;</li>
</ol>
</li>
<li><p>scrapy_splash&#x7684;&#x7279;&#x5B9A;&#x914D;&#x7F6E;</p>
<pre><code class="lang-python"> SPLASH_URL = <span class="hljs-string">&apos;http://127.0.0.1:8050&apos;</span>
 DOWNLOADER_MIDDLEWARES = {
     <span class="hljs-string">&apos;scrapy_splash.SplashCookiesMiddleware&apos;</span>: <span class="hljs-number">723</span>,
     <span class="hljs-string">&apos;scrapy_splash.SplashMiddleware&apos;</span>: <span class="hljs-number">725</span>,
     <span class="hljs-string">&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;</span>: <span class="hljs-number">810</span>,
 }
 DUPEFILTER_CLASS = <span class="hljs-string">&apos;scrapy_splash.SplashAwareDupeFilter&apos;</span>
 HTTPCACHE_STORAGE = <span class="hljs-string">&apos;scrapy_splash.SplashAwareFSCacheStorage&apos;</span>
</code></pre>
</li>
</ol>
<hr>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; ITCast all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x300C;Revision Time:
2019-02-28 02:05:09&#x300D;
</span></footer>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html" class="navigation navigation-prev " aria-label="Previous page: scrapy_redis原理分析并实现断点续爬以及分布式爬虫"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html" class="navigation navigation-next " aria-label="Next page: scrapy的日志信息与配置"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"disqus":{"shortName":"gitbookuse"},"github":{"url":"https://github.com/dododream"},"search-pro":{"cutWordLib":"nodejieba","defineWord":["gitbook-use"]},"sharing":{"weibo":true,"facebook":true,"twitter":true,"google":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"tbfed-pagefooter":{"copyright":"Copyright © ITCast","modify_label":"「Revision Time:","modify_format":"YYYY-MM-DD HH:mm:ss」"},"baidu":{"token":"ff100361cdce95dd4c8fb96b4009f7bc"},"sitemap":{"hostname":"http://www.treenewbee.top"},"donate":{"wechat":"http://weixin.png","alipay":"http://alipay.png","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"edit-link":{"base":"https://github.com/dododream/edit","label":"Edit This Page"},"splitter":{},"toggle-chapters":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
    </body>
    <!-- End of book Python爬虫课程讲义 -->
</html>
