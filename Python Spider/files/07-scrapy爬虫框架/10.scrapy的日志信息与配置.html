<!DOCTYPE HTML>
<html lang="en" >
    <!-- Start book Python爬虫课程讲义 -->
    <head>
        <!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy的日志信息与配置 | Python爬虫课程讲义</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        <meta name="author" content="BigCat">
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-tbfed-pagefooter/footer.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html" />
    
    
    <link rel="prev" href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html" />
    

        <!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
        
    <div class="book"
        data-level="7.10"
        data-chapter-title="scrapy的日志信息与配置"
        data-filepath="files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.md"
        data-basepath="../.."
        data-revision="Thu Feb 28 2019 03:09:16 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        传智播客Python学科爬虫课件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="files/01-爬虫基础/index.html">
            
                
                    <a href="../../files/01-爬虫基础/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        网络爬虫知识基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="files/01-爬虫基础/1.爬虫概述.html">
            
                
                    <a href="../../files/01-爬虫基础/1.爬虫概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫概述与分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
            
                
                    <a href="../../files/01-爬虫基础/2.通用爬虫和聚焦爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        (了解) 通用爬虫和聚焦爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="files/01-爬虫基础/3.爬虫基础知识.html">
            
                
                    <a href="../../files/01-爬虫基础/3.爬虫基础知识.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        爬虫基础知识
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="files/01-爬虫基础/4.http协议复习.html">
            
                
                    <a href="../../files/01-爬虫基础/4.http协议复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        (复习) http协议复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="files/02-requests模块/index.html">
            
                
                    <a href="../../files/02-requests模块/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        HTTP请求处理工具：requests
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="files/02-requests模块/requests模块1.html">
            
                
                    <a href="../../files/02-requests模块/requests模块1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        requests模块处理的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="files/02-requests模块/requests模块2.html">
            
                
                    <a href="../../files/02-requests模块/requests模块2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        requests模块处理Cookie和Proxy高级功能
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="files/02-requests模块/requests模块3.html">
            
                
                    <a href="../../files/02-requests模块/requests模块3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        requests模块处理post请求与session会话保持
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="files/03-数据提取/index.html">
            
                
                    <a href="../../files/03-数据提取/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        HTTP数据提取工具：jsonpath 和 lxml/xpath
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="files/03-数据提取/1.数据提取概述.html">
            
                
                    <a href="../../files/03-数据提取/1.数据提取概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        数据提取概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="files/03-数据提取/2.数据提取-jsonpath模块.html">
            
                
                    <a href="../../files/03-数据提取/2.数据提取-jsonpath模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        数据提取-jsonpath模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="files/03-数据提取/3.数据提取-lxml模块.html">
            
                
                    <a href="../../files/03-数据提取/3.数据提取-lxml模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        数据提取-lxml模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="files/04-selenium的使用/index.html">
            
                
                    <a href="../../files/04-selenium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        web自动化测试工具：selenium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="files/04-selenium的使用/1.selenium的介绍.html">
            
                
                    <a href="../../files/04-selenium的使用/1.selenium的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        selenium的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
            
                
                    <a href="../../files/04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium定位获取标签对象并提取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="files/04-selenium的使用/3.selenium的其它使用方法.html">
            
                
                    <a href="../../files/04-selenium的使用/3.selenium的其它使用方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        selenium的其它使用方法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="files/05-抓包、反爬与反爬解决方案/index.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        抓包、反爬与反爬解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/1.常见的反爬手段、原理以及应对思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        常见的反爬手段、原理以及应对思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/2.打码平台处理验证码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        打码平台处理验证码
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/3.chrome浏览器的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        chrome浏览器的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/4.js2py模块的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        js2py模块的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.5" data-path="files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
            
                
                    <a href="../../files/05-抓包、反爬与反爬解决方案/5.cookie池和代理池.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        cookie池和代理池
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="files/06-mongodb数据库/index.html">
            
                
                    <a href="../../files/06-mongodb数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        MongoDB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="files/06-mongodb数据库/1.mongodb介绍和安装.html">
            
                
                    <a href="../../files/06-mongodb数据库/1.mongodb介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        mongodb介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="files/06-mongodb数据库/2.mongodb的简单使用.html">
            
                
                    <a href="../../files/06-mongodb数据库/2.mongodb的简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        mongodb的简单使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="files/06-mongodb数据库/3.mongodb的增删改查.html">
            
                
                    <a href="../../files/06-mongodb数据库/3.mongodb的增删改查.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        mongodb的增删改查
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="files/06-mongodb数据库/4.mongodb的索引操作.html">
            
                
                    <a href="../../files/06-mongodb数据库/4.mongodb的索引操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.4.</b>
                        
                        mongodb的索引操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="files/06-mongodb数据库/5.mongodb的权限管理.html">
            
                
                    <a href="../../files/06-mongodb数据库/5.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.5.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.6" data-path="files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
            
                
                    <a href="../../files/06-mongodb数据库/6.mongodb和python交互（pymongo模块的使用）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.6.</b>
                        
                        mongodb和python交互（pymongo模块的使用）
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="files/07-scrapy爬虫框架/index.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Scrapy爬虫框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.3.</b>
                        
                        scrapy构造并发送请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/4.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.4.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/5.scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/6.scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.6.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.7" data-path="files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.7.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.8" data-path="files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.8.</b>
                        
                        scrapy_redis原理分析并实现断点续爬以及分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.9" data-path="files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.9.</b>
                        
                        scrapy_splash组件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7.10" data-path="files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.10.</b>
                        
                        scrapy的日志信息与配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.11" data-path="files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
            
                
                    <a href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.11.</b>
                        
                        scrapyd部署scrapy项目
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="files/08-appium的使用/index.html">
            
                
                    <a href="../../files/08-appium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        移动端APP自动化测试工具：appium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="files/08-appium的使用/1.appium环境安装.html">
            
                
                    <a href="../../files/08-appium的使用/1.appium环境安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        appium环境安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
            
                
                    <a href="../../files/08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        利用appium自动控制移动设备并提取数据
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="files/09-项目-12306购票（requests）/index.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        项目：12306购票（requests）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/1.12306购票抓包分析以及任务分解.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        12306购票抓包分析以及任务分解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/2.处理验证码并完成登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        处理验证码并完成登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.3" data-path="files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/3.解析车站信息以及车辆信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.3.</b>
                        
                        解析车站信息以及车辆信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.4" data-path="files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/4.预定订单初始化、解析用户信息以及坐席信息.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.4.</b>
                        
                        预定订单初始化、解析用户信息以及坐席信息
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.5" data-path="files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/5.构造时间参数以及下单购票.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.5.</b>
                        
                        构造时间参数以及下单购票
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.6" data-path="files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
            
                
                    <a href="../../files/09-项目-12306购票（requests）/6.测试运行以及完整代码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.6.</b>
                        
                        测试运行以及完整代码
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="files/10-项目-国家企业公示网（selenium）/index.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        项目：国家企业公示网（selenium）
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="10.1" data-path="files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/1.项目分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.1.</b>
                        
                        项目分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/2.webapi实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.2.</b>
                        
                        webapi实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/3.node_server节点任务调度.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.3.</b>
                        
                        node_server节点任务调度
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/4.crawler爬虫抓取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.4.</b>
                        
                        crawler爬虫抓取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
            
                
                    <a href="../../files/10-项目-国家企业公示网（selenium）/5.运行效果.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.5.</b>
                        
                        运行效果
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="11" data-path="files/duanzi/duanzi.html">
            
                
                    <a href="../../files/duanzi/duanzi.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        课余段子
                    </a>
            
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >Python爬虫课程讲义</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x4E0E;&#x914D;&#x7F6E;">scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x4E0E;&#x914D;&#x7F6E;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;">&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;</h5>
<ul>
<li>&#x4E86;&#x89E3; scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;</li>
<li>&#x638C;&#x63E1; scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;</li>
<li>&#x638C;&#x63E1; scrapy_redis&#x914D;&#x7F6E;</li>
<li>&#x4E86;&#x89E3;scrapy_splash&#x914D;&#x7F6E;</li>
<li>&#x4E86;&#x89E3;scrapy_redis&#x548C;scrapy_splash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;</li>
</ul>
<hr>
<h3 id="1-&#x4E86;&#x89E3;scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;">1. &#x4E86;&#x89E3;scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;</h3>
<p><img src="images/10.1.scrapy_debug.png" width="100%"></p>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;-scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3; scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;</h5>
<hr>
<h3 id="2-scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;">2. scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;</h3>
<ul>
<li>ROBOTSTXT_OBEY &#x662F;&#x5426;&#x9075;&#x5B88;robots&#x534F;&#x8BAE;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;&#x9075;&#x5B88;<ul>
<li>&#x5173;&#x4E8E;robots&#x534F;&#x8BAE;<ol>
<li>&#x5728;&#x767E;&#x5EA6;&#x641C;&#x7D22;&#x4E2D;&#xFF0C;&#x4E0D;&#x80FD;&#x641C;&#x7D22;&#x5230;&#x6DD8;&#x5B9D;&#x7F51;&#x4E2D;&#x67D0;&#x4E00;&#x4E2A;&#x5177;&#x4F53;&#x7684;&#x5546;&#x54C1;&#x7684;&#x8BE6;&#x60C5;&#x9875;&#x9762;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;robots&#x534F;&#x8BAE;&#x5728;&#x8D77;&#x4F5C;&#x7528;</li>
<li>Robots&#x534F;&#x8BAE;&#xFF1A;&#x7F51;&#x7AD9;&#x901A;&#x8FC7;Robots&#x534F;&#x8BAE;&#x544A;&#x8BC9;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x54EA;&#x4E9B;&#x9875;&#x9762;&#x53EF;&#x4EE5;&#x6293;&#x53D6;&#xFF0C;&#x54EA;&#x4E9B;&#x9875;&#x9762;&#x4E0D;&#x80FD;&#x6293;&#x53D6;&#xFF0C;&#x4F46;&#x5B83;&#x4EC5;&#x4EC5;&#x662F;&#x4E92;&#x8054;&#x7F51;&#x4E2D;&#x7684;&#x4E00;&#x822C;&#x7EA6;&#x5B9A;</li>
<li>&#x4F8B;&#x5982;&#xFF1A;<a href="https://www.taobao.com/robots.txt" target="_blank">&#x6DD8;&#x5B9D;&#x7684;robots&#x534F;&#x8BAE;</a></li>
</ol>
</li>
</ul>
</li>
</ul>
<ul>
<li>USER_AGENT &#x8BBE;&#x7F6E;ua</li>
<li>DEFAULT_REQUEST_HEADERS &#x8BBE;&#x7F6E;&#x9ED8;&#x8BA4;&#x8BF7;&#x6C42;&#x5934;&#xFF0C;&#x8FD9;&#x91CC;&#x52A0;&#x5165;&#x4E86;USER_AGENT&#x5C06;&#x4E0D;&#x8D77;&#x4F5C;&#x7528;</li>
</ul>
<ul>
<li>ITEM_PIPELINES &#x7BA1;&#x9053;&#xFF0C;&#x5DE6;&#x4F4D;&#x7F6E;&#x53F3;&#x6743;&#x91CD;&#xFF1A;&#x6743;&#x91CD;&#x503C;&#x8D8A;&#x5C0F;&#xFF0C;&#x8D8A;&#x4F18;&#x5148;&#x6267;&#x884C;</li>
<li>SPIDER_MIDDLEWARES &#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#xFF0C;&#x8BBE;&#x7F6E;&#x8FC7;&#x7A0B;&#x548C;&#x7BA1;&#x9053;&#x76F8;&#x540C;</li>
<li>DOWNLOADER_MIDDLEWARES &#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</li>
</ul>
<ul>
<li>COOKIES_ENABLED &#x9ED8;&#x8BA4;&#x4E3A;True&#x8868;&#x793A;&#x5F00;&#x542F;cookie&#x4F20;&#x9012;&#x529F;&#x80FD;&#xFF0C;&#x5373;&#x6BCF;&#x6B21;&#x8BF7;&#x6C42;&#x5E26;&#x4E0A;&#x524D;&#x4E00;&#x6B21;&#x7684;cookie&#xFF0C;&#x505A;&#x72B6;&#x6001;&#x4FDD;&#x6301;</li>
<li>COOKIES_DEBUG &#x9ED8;&#x8BA4;&#x4E3A;False&#x8868;&#x793A;&#x65E5;&#x5FD7;&#x4E2D;&#x4E0D;&#x663E;&#x793A;cookie&#x7684;&#x4F20;&#x9012;&#x8FC7;&#x7A0B;</li>
</ul>
<ul>
<li>LOG_LEVEL &#x9ED8;&#x8BA4;&#x4E3A;DEBUG&#xFF0C;&#x63A7;&#x5236;&#x65E5;&#x5FD7;&#x7684;&#x7B49;&#x7EA7;<ul>
<li>LOG_LEVEL = &quot;WARNING&quot;</li>
</ul>
</li>
<li>LOG_FILE &#x8BBE;&#x7F6E;log&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x7684;&#x4FDD;&#x5B58;&#x8DEF;&#x5F84;&#xFF0C;&#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x8BE5;&#x53C2;&#x6570;&#xFF0C;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x5C06;&#x5199;&#x5165;&#x6587;&#x4EF6;&#xFF0C;&#x7EC8;&#x7AEF;&#x5C06;&#x4E0D;&#x518D;&#x663E;&#x793A;&#xFF0C;&#x4E14;&#x53D7;&#x5230;LOG_LEVEL&#x65E5;&#x5FD7;&#x7B49;&#x7EA7;&#x7684;&#x9650;&#x5236;<ul>
<li>LOG_FILE = &quot;./test.log&quot;</li>
</ul>
</li>
<li>CONCURRENT_REQUESTS &#x8BBE;&#x7F6E;&#x5E76;&#x53D1;&#x8BF7;&#x6C42;&#x7684;&#x6570;&#x91CF;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;16&#x4E2A;</li>
<li>DOWNLOAD_DELAY &#x4E0B;&#x8F7D;&#x5EF6;&#x8FDF;&#xFF0C;&#x9ED8;&#x8BA4;&#x65E0;&#x5EF6;&#x8FDF;&#xFF0C;&#x5355;&#x4F4D;&#x4E3A;&#x79D2;</li>
</ul>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1;-scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1; scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;</h5>
<hr>
<h3 id="3-scrapyredis&#x914D;&#x7F6E;">3. scrapy_redis&#x914D;&#x7F6E;</h3>
<ul>
<li>DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot; # &#x6307;&#x7EB9;&#x751F;&#x6210;&#x4EE5;&#x53CA;&#x53BB;&#x91CD;&#x7C7B;</li>
<li>SCHEDULER = &quot;scrapy_redis.scheduler.Scheduler&quot; # &#x8C03;&#x5EA6;&#x5668;&#x7C7B;</li>
<li>SCHEDULER_PERSIST = True # &#x6301;&#x4E45;&#x5316;&#x8BF7;&#x6C42;&#x961F;&#x5217;&#x548C;&#x6307;&#x7EB9;&#x96C6;&#x5408;</li>
<li>ITEM_PIPELINES = {&apos;scrapy_redis.pipelines.RedisPipeline&apos;: 400} # &#x6570;&#x636E;&#x5B58;&#x5165;redis&#x7684;&#x7BA1;&#x9053;</li>
<li>REDIS_URL = &quot;redis://host:port&quot; # redis&#x7684;url</li>
</ul>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1;-scrapyredis&#x914D;&#x7F6E;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x638C;&#x63E1; scrapy_redis&#x914D;&#x7F6E;</h5>
<hr>
<h3 id="4-scrapysplash&#x914D;&#x7F6E;">4. scrapy_splash&#x914D;&#x7F6E;</h3>
<pre><code class="lang-python">SPLASH_URL = <span class="hljs-string">&apos;http://127.0.0.1:8050&apos;</span>
DOWNLOADER_MIDDLEWARES = {
<span class="hljs-string">&apos;scrapy_splash.SplashCookiesMiddleware&apos;</span>: <span class="hljs-number">723</span>,
<span class="hljs-string">&apos;scrapy_splash.SplashMiddleware&apos;</span>: <span class="hljs-number">725</span>,
<span class="hljs-string">&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;</span>: <span class="hljs-number">810</span>,
}
DUPEFILTER_CLASS = <span class="hljs-string">&apos;scrapy_splash.SplashAwareDupeFilter&apos;</span> 
HTTPCACHE_STORAGE = <span class="hljs-string">&apos;scrapy_splash.SplashAwareFSCacheStorage&apos;</span>
</code></pre>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;scrapysplash&#x914D;&#x7F6E;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;scrapy_splash&#x914D;&#x7F6E;</h5>
<hr>
<h3 id="5-scrapyredis&#x548C;scrapysplash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;">5. scrapy_redis&#x548C;scrapy_splash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;</h3>
<h4 id="51-&#x539F;&#x7406;">5.1 &#x539F;&#x7406;</h4>
<ul>
<li>scrapy-redis&#x4E2D;&#x914D;&#x7F6E;&#x4E86;&#x201D;DUPEFILTER_CLASS&#x201D; : &#x201C;scrapy_redis.dupefilter.RFPDupeFilter&#x201D;&#xFF0C;&#x4E0E;scrapy-splash&#x914D;&#x7F6E;&#x7684;DUPEFILTER_CLASS = &#x2018;scrapy_splash.SplashAwareDupeFilter&#x2019; &#x76F8;&#x51B2;&#x7A81;&#xFF01;</li>
<li>&#x67E5;&#x770B;&#x4E86;scrapy_splash.SplashAwareDupeFilter&#x6E90;&#x7801;&#x540E;&#xFF0C;&#x53D1;&#x73B0;&#x4ED6;&#x7EE7;&#x627F;&#x4E86;scrapy.dupefilter.RFPDupeFilter&#xFF0C;&#x5E76;&#x91CD;&#x5199;&#x4E86;request_fingerprint()&#x65B9;&#x6CD5;&#x3002;</li>
<li>&#x6BD4;&#x8F83;scrapy.dupefilter.RFPDupeFilter&#x548C;scrapy_redis.dupefilter.RFPDupeFilter&#x4E2D;&#x7684;request_fingerprint()&#x65B9;&#x6CD5;&#x540E;&#xFF0C;&#x53D1;&#x73B0;&#x662F;&#x4E00;&#x6837;&#x7684;&#xFF0C;&#x56E0;&#x6B64;&#x91CD;&#x5199;&#x4E86;&#x4E00;&#x4E2A;SplashAwareDupeFilter&#xFF0C;&#x7EE7;&#x627F;scrapy_redis.dupefilter.RFPDupeFilter&#xFF0C;&#x5176;&#x4ED6;&#x4EE3;&#x7801;&#x4E0D;&#x53D8;&#x3002;</li>
</ul>
<h4 id="52-&#x91CD;&#x5199;dupefilter&#x53BB;&#x91CD;&#x7C7B;&#xFF0C;&#x5E76;&#x5728;settingspy&#x4E2D;&#x4F7F;&#x7528;">5.2 &#x91CD;&#x5199;dupefilter&#x53BB;&#x91CD;&#x7C7B;&#xFF0C;&#x5E76;&#x5728;settings.py&#x4E2D;&#x4F7F;&#x7528;</h4>
<h5 id="521-&#x91CD;&#x5199;&#x53BB;&#x91CD;&#x7C7B;">5.2.1 &#x91CD;&#x5199;&#x53BB;&#x91CD;&#x7C7B;</h5>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import

<span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy

<span class="hljs-keyword">from</span> scrapy.utils.request <span class="hljs-keyword">import</span> request_fingerprint
<span class="hljs-keyword">from</span> scrapy.utils.url <span class="hljs-keyword">import</span> canonicalize_url

<span class="hljs-keyword">from</span> scrapy_splash.utils <span class="hljs-keyword">import</span> dict_hash

<span class="hljs-keyword">from</span> scrapy_redis.dupefilter <span class="hljs-keyword">import</span> RFPDupeFilter


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">splash_request_fingerprint</span><span class="hljs-params">(request, include_headers=None)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot; Request fingerprint which takes &apos;splash&apos; meta key into account &quot;&quot;&quot;</span>

    fp = request_fingerprint(request, include_headers=include_headers)
    <span class="hljs-keyword">if</span> <span class="hljs-string">&apos;splash&apos;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> request.meta:
        <span class="hljs-keyword">return</span> fp

    splash_options = deepcopy(request.meta[<span class="hljs-string">&apos;splash&apos;</span>])
    args = splash_options.setdefault(<span class="hljs-string">&apos;args&apos;</span>, {})

    <span class="hljs-keyword">if</span> <span class="hljs-string">&apos;url&apos;</span> <span class="hljs-keyword">in</span> args:
        args[<span class="hljs-string">&apos;url&apos;</span>] = canonicalize_url(args[<span class="hljs-string">&apos;url&apos;</span>], keep_fragments=<span class="hljs-keyword">True</span>)

    <span class="hljs-keyword">return</span> dict_hash(splash_options, fp)


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SplashAwareDupeFilter</span><span class="hljs-params">(RFPDupeFilter)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    DupeFilter that takes &apos;splash&apos; meta key in account.
    It should be used with SplashMiddleware.
    &quot;&quot;&quot;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">request_fingerprint</span><span class="hljs-params">(self, request)</span>:</span>
        <span class="hljs-keyword">return</span> splash_request_fingerprint(request)


<span class="hljs-string">&quot;&quot;&quot;&#x4EE5;&#x4E0A;&#x4E3A;&#x91CD;&#x5199;&#x7684;&#x53BB;&#x91CD;&#x7C7B;&#xFF0C;&#x4E0B;&#x8FB9;&#x4E3A;&#x722C;&#x866B;&#x4EE3;&#x7801;&quot;&quot;&quot;</span>

<span class="hljs-keyword">from</span> scrapy_redis.spiders <span class="hljs-keyword">import</span> RedisSpider
<span class="hljs-keyword">from</span> scrapy_splash <span class="hljs-keyword">import</span> SplashRequest


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SplashAndRedisSpider</span><span class="hljs-params">(RedisSpider)</span>:</span>
    name = <span class="hljs-string">&apos;splash_and_redis&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;baidu.com&apos;</span>]

    <span class="hljs-comment"># start_urls = [&apos;https://www.baidu.com/s?wd=13161933309&apos;]</span>
    redis_key = <span class="hljs-string">&apos;splash_and_redis&apos;</span>
    <span class="hljs-comment"># lpush splash_and_redis &apos;https://www.baidu.com&apos;</span>

    <span class="hljs-comment"># &#x5206;&#x5E03;&#x5F0F;&#x7684;&#x8D77;&#x59CB;&#x7684;url&#x4E0D;&#x80FD;&#x4F7F;&#x7528;splash&#x670D;&#x52A1;!</span>
    <span class="hljs-comment"># &#x9700;&#x8981;&#x91CD;&#x5199;dupefilter&#x53BB;&#x91CD;&#x7C7B;!</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">yield</span> SplashRequest(<span class="hljs-string">&apos;https://www.baidu.com/s?wd=13161933309&apos;</span>,
                            callback=self.parse_splash,
                            args={<span class="hljs-string">&apos;wait&apos;</span>: <span class="hljs-number">10</span>}, <span class="hljs-comment"># &#x6700;&#x5927;&#x8D85;&#x65F6;&#x65F6;&#x95F4;&#xFF0C;&#x5355;&#x4F4D;&#xFF1A;&#x79D2;</span>
                            endpoint=<span class="hljs-string">&apos;render.html&apos;</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;splash&#x670D;&#x52A1;&#x7684;&#x56FA;&#x5B9A;&#x53C2;&#x6570;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_splash</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;splash_and_redis.html&apos;</span>, <span class="hljs-string">&apos;w&apos;</span>) <span class="hljs-keyword">as</span> f:
            f.write(response.body.decode())
</code></pre>
<h5 id="522-scrapyredis&#x548C;scrapysplash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;">5.2.2 scrapy_redis&#x548C;scrapy_splash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;</h5>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6E32;&#x67D3;&#x670D;&#x52A1;&#x7684;url</span>
SPLASH_URL = <span class="hljs-string">&apos;http://127.0.0.1:8050&apos;</span>
<span class="hljs-comment"># &#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;</span>
DOWNLOADER_MIDDLEWARES = {
    <span class="hljs-string">&apos;scrapy_splash.SplashCookiesMiddleware&apos;</span>: <span class="hljs-number">723</span>,
    <span class="hljs-string">&apos;scrapy_splash.SplashMiddleware&apos;</span>: <span class="hljs-number">725</span>,
    <span class="hljs-string">&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;</span>: <span class="hljs-number">810</span>,
}
<span class="hljs-comment"># &#x4F7F;&#x7528;Splash&#x7684;Http&#x7F13;&#x5B58;</span>
HTTPCACHE_STORAGE = <span class="hljs-string">&apos;scrapy_splash.SplashAwareFSCacheStorage&apos;</span>

<span class="hljs-comment"># &#x53BB;&#x91CD;&#x8FC7;&#x6EE4;&#x5668;</span>
<span class="hljs-comment"># DUPEFILTER_CLASS = &apos;scrapy_splash.SplashAwareDupeFilter&apos;</span>
<span class="hljs-comment"># DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot; # &#x6307;&#x7EB9;&#x751F;&#x6210;&#x4EE5;&#x53CA;&#x53BB;&#x91CD;&#x7C7B;</span>
DUPEFILTER_CLASS = <span class="hljs-string">&apos;test_splash.spiders.splash_and_redis.SplashAwareDupeFilter&apos;</span> <span class="hljs-comment"># &#x6DF7;&#x5408;&#x53BB;&#x91CD;&#x7C7B;&#x7684;&#x4F4D;&#x7F6E;</span>

SCHEDULER = <span class="hljs-string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span> <span class="hljs-comment"># &#x8C03;&#x5EA6;&#x5668;&#x7C7B;</span>
SCHEDULER_PERSIST = <span class="hljs-keyword">True</span> <span class="hljs-comment"># &#x6301;&#x4E45;&#x5316;&#x8BF7;&#x6C42;&#x961F;&#x5217;&#x548C;&#x6307;&#x7EB9;&#x96C6;&#x5408;, scrapy_redis&#x548C;scrapy_splash&#x6DF7;&#x7528;&#x4F7F;&#x7528;splash&#x7684;DupeFilter!</span>
ITEM_PIPELINES = {<span class="hljs-string">&apos;scrapy_redis.pipelines.RedisPipeline&apos;</span>: <span class="hljs-number">400</span>} <span class="hljs-comment"># &#x6570;&#x636E;&#x5B58;&#x5165;redis&#x7684;&#x7BA1;&#x9053;</span>
REDIS_URL = <span class="hljs-string">&quot;redis://127.0.0.1:6379&quot;</span> <span class="hljs-comment"># redis&#x7684;url</span>
</code></pre>
<h5 id="&#x6CE8;&#x610F;&#xFF1A;">&#x6CE8;&#x610F;&#xFF1A;</h5>
<ul>
<li>scrapy_redis&#x5206;&#x5E03;&#x5F0F;&#x722C;&#x866B;&#x5728;&#x4E1A;&#x52A1;&#x903B;&#x8F91;&#x7ED3;&#x675F;&#x540E;&#x5E76;&#x4E0D;&#x80FD;&#x591F;&#x81EA;&#x52A8;&#x9000;&#x51FA;</li>
<li>&#x91CD;&#x5199;&#x7684;dupefilter&#x53BB;&#x91CD;&#x7C7B;&#x53EF;&#x4EE5;&#x81EA;&#x5B9A;&#x4E49;&#x4F4D;&#x7F6E;&#xFF0C;&#x4E5F;&#x987B;&#x5728;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x5199;&#x5165;&#x76F8;&#x5E94;&#x7684;&#x8DEF;&#x5F84;</li>
</ul>
<hr>
<h5 id="&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;scrapyredis&#x548C;scrapysplash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;">&#x77E5;&#x8BC6;&#x70B9;&#xFF1A;&#x4E86;&#x89E3;scrapy_redis&#x548C;scrapy_splash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;</h5>
<hr>
<h3 id="6-&#x4E86;&#x89E3;scrapy&#x7684;&#x5176;&#x4ED6;&#x914D;&#x7F6E;">6. &#x4E86;&#x89E3;scrapy&#x7684;&#x5176;&#x4ED6;&#x914D;&#x7F6E;</h3>
<ul>
<li>&#x5176;&#x4ED6;&#x8BBE;&#x7F6E;&#x53C2;&#x8003;&#xFF1A;<a href="https://www.jianshu.com/p/df9c0d1e9087" target="_blank">https://www.jianshu.com/p/df9c0d1e9087</a></li>
</ul>
<hr>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<ol>
<li>&#x4E86;&#x89E3;scrapy&#x7684;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;</li>
<li>&#x638C;&#x63E1;scrapy&#x7684;&#x5E38;&#x7528;&#x914D;&#x7F6E;</li>
<li>&#x638C;&#x63E1;scrapy_redis&#x914D;&#x7F6E;</li>
<li>&#x4E86;&#x89E3;scrapy_splash&#x914D;&#x7F6E;</li>
<li>&#x4E86;&#x89E3;scrapy_redis&#x548C;scrapy_splash&#x914D;&#x5408;&#x4F7F;&#x7528;&#x7684;&#x914D;&#x7F6E;</li>
</ol>
<hr>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; ITCast all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x300C;Revision Time:
2019-02-28 02:05:47&#x300D;
</span></footer>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../files/07-scrapy爬虫框架/9.scrapy_splash组件的使用.html" class="navigation navigation-prev " aria-label="Previous page: scrapy_splash组件的使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../files/07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html" class="navigation navigation-next " aria-label="Next page: scrapyd部署scrapy项目"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"disqus":{"shortName":"gitbookuse"},"github":{"url":"https://github.com/dododream"},"search-pro":{"cutWordLib":"nodejieba","defineWord":["gitbook-use"]},"sharing":{"weibo":true,"facebook":true,"twitter":true,"google":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"tbfed-pagefooter":{"copyright":"Copyright © ITCast","modify_label":"「Revision Time:","modify_format":"YYYY-MM-DD HH:mm:ss」"},"baidu":{"token":"ff100361cdce95dd4c8fb96b4009f7bc"},"sitemap":{"hostname":"http://www.treenewbee.top"},"donate":{"wechat":"http://weixin.png","alipay":"http://alipay.png","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"edit-link":{"base":"https://github.com/dododream/edit","label":"Edit This Page"},"splitter":{},"toggle-chapters":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
    </body>
    <!-- End of book Python爬虫课程讲义 -->
</html>
